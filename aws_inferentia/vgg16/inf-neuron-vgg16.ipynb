{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AWS Inferentia inference on Amazon EC2 Inf1 instance\n",
    "This example demonstrates AWS Inferentia inference with TensorFlow and AWS Neuron SDK compiler and runtime\n",
    "\n",
    "This example was tested on Amazon EC2 `inf1.xlarge` the following AWS Deep Learning AMI: \n",
    "`Deep Learning AMI (Ubuntu 18.04) Version 35.0`\n",
    "\n",
    "Run this notebook using the following conda environment:\n",
    "`aws_neuron_tensorflow_p36`\n",
    "\n",
    "Prepare your imagenet validation TFRecord files using the following helper script:\n",
    "https://github.com/tensorflow/models/blob/archive/research/inception/inception/data/download_and_preprocess_imagenet.sh\n",
    "\n",
    "Save it to `/home/ubuntu/datasets/` or update the dataset location in the `get_dataset()` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install matplotlib pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n"
     ]
    }
   ],
   "source": [
    "!/opt/aws/neuron/bin/neuron-cli reset\n",
    "import os\n",
    "import time\n",
    "import shutil\n",
    "import json\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow.neuron as tfn\n",
    "import tensorflow.compat.v1.keras as keras\n",
    "from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from concurrent import futures\n",
    "from itertools import compress\n",
    "\n",
    "print('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/tensorflow/tensorflow/issues/29931\n",
    "temp = tf.zeros([8, 224, 224, 3])\n",
    "_ = tf.keras.applications.vgg16.preprocess_input(temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resnet50 FP32 saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/aws_neuron_tensorflow_p36/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    }
   ],
   "source": [
    "# # Export SavedModel\n",
    "model_type = 'vgg16'\n",
    "\n",
    "saved_model_dir = f'{model_type}_saved_model'\n",
    "shutil.rmtree(saved_model_dir, ignore_errors=True)\n",
    "\n",
    "keras.backend.set_learning_phase(0)\n",
    "model = VGG16(weights='imagenet')\n",
    "# tf.saved_model.simple_save(session = keras.backend.get_session(),\n",
    "#                            export_dir = saved_model_dir,\n",
    "#                            inputs = {'input_1:0': model.inputs[0]},\n",
    "#                            outputs = {'probs/Softmax:0': model.outputs[0]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile models with different batch sizes and cores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_inf1_model(saved_model_dir, inf1_model_dir, batch_size=1, num_cores=1, use_static_weights=False):\n",
    "    print(f'-----------batch size: {batch_size}, num cores: {num_cores}----------')\n",
    "    print('Compiling...')\n",
    "    \n",
    "    compiled_model_dir = f'{model_type}_batch_{batch_size}_inf1_cores_{num_cores}'\n",
    "    inf1_compiled_model_dir = os.path.join(inf1_model_dir, compiled_model_dir)\n",
    "    shutil.rmtree(inf1_compiled_model_dir, ignore_errors=True)\n",
    "\n",
    "    example_input = np.zeros([batch_size,224,224,3], dtype='float32')\n",
    "\n",
    "    compiler_args = ['--verbose','1', '--neuroncore-pipeline-cores', str(num_cores)]\n",
    "    if use_static_weights:\n",
    "        compiler_args.append('--static-weights')\n",
    "    \n",
    "    start_time = time.time()\n",
    "    compiled_res = tfn.saved_model.compile(model_dir = saved_model_dir,\n",
    "                            model_feed_dict={'input_1:0': example_input},\n",
    "                            new_model_dir = inf1_compiled_model_dir,\n",
    "                            dynamic_batch_size=True,\n",
    "                            compiler_args = compiler_args)\n",
    "    print(f'Compile time: {time.time() - start_time}')\n",
    "    \n",
    "    compile_success = False\n",
    "    perc_on_inf = compiled_res['OnNeuronRatio'] * 100\n",
    "    if perc_on_inf > 50:\n",
    "        compile_success = True\n",
    "            \n",
    "    print(inf1_compiled_model_dir)\n",
    "    print(compiled_res)\n",
    "    print('----------- Done! ----------- \\n')\n",
    "    \n",
    "    return compile_success"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use `tf.data` to read ImageNet validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deserialize_image_record(record):\n",
    "    feature_map = {'image/encoded': tf.io.FixedLenFeature([], tf.string, ''),\n",
    "                  'image/class/label': tf.io.FixedLenFeature([1], tf.int64, -1),\n",
    "                  'image/class/text': tf.io.FixedLenFeature([], tf.string, '')}\n",
    "    obj = tf.io.parse_single_example(serialized=record, features=feature_map)\n",
    "    imgdata = obj['image/encoded']\n",
    "    label = tf.cast(obj['image/class/label'], tf.int32)   \n",
    "    label_text = tf.cast(obj['image/class/text'], tf.string)   \n",
    "    return imgdata, label, label_text\n",
    "\n",
    "def val_preprocessing(record):\n",
    "    imgdata, label, label_text = deserialize_image_record(record)\n",
    "    label -= 1\n",
    "    image = tf.io.decode_jpeg(imgdata, channels=3, \n",
    "                              fancy_upscaling=False, \n",
    "                              dct_method='INTEGER_FAST')\n",
    "\n",
    "    shape = tf.shape(image)\n",
    "    height = tf.cast(shape[0], tf.float32)\n",
    "    width = tf.cast(shape[1], tf.float32)\n",
    "    side = tf.cast(tf.convert_to_tensor(256, dtype=tf.int32), tf.float32)\n",
    "\n",
    "    scale = tf.cond(tf.greater(height, width),\n",
    "                  lambda: side / width,\n",
    "                  lambda: side / height)\n",
    "    \n",
    "    new_height = tf.cast(tf.math.rint(height * scale), tf.int32)\n",
    "    new_width = tf.cast(tf.math.rint(width * scale), tf.int32)\n",
    "    \n",
    "    image = tf.image.resize(image, [new_height, new_width], method='bicubic')\n",
    "    image = tf.image.resize_with_crop_or_pad(image, 224, 224)\n",
    "    \n",
    "    image = tf.keras.applications.vgg16.preprocess_input(image)\n",
    "    \n",
    "    return image, label, label_text\n",
    "\n",
    "def get_dataset(batch_size, use_cache=False):\n",
    "    data_dir = '/home/ubuntu/datasets/*'\n",
    "    files = tf.io.gfile.glob(os.path.join(data_dir))\n",
    "    dataset = tf.data.TFRecordDataset(files)\n",
    "    \n",
    "    dataset = dataset.map(map_func=val_preprocessing, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    dataset = dataset.batch(batch_size=batch_size)\n",
    "    dataset = dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "    dataset = dataset.repeat(count=1)\n",
    "    \n",
    "    if use_cache:\n",
    "        shutil.rmtree('tfdatacache', ignore_errors=True)\n",
    "        os.mkdir('tfdatacache')\n",
    "        dataset = dataset.cache(f'./tfdatacache/imagenet_val')\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single AWS Inferentia chip execution\n",
    "* Single core compiled models with automatic data parallel model upto 4 cores\n",
    "* Multi-core compiled models for pipeline execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def inf1_predict_benchmark_single_threaded(neuron_saved_model_name, batch_size, user_batch_size, num_cores, use_cache=False, warm_up=10):\n",
    "    print(f'Running model {neuron_saved_model_name}, user_batch_size: {user_batch_size}\\n')\n",
    "\n",
    "    model_inf1 = tf.contrib.predictor.from_saved_model(neuron_saved_model_name)\n",
    "\n",
    "    iter_times = []\n",
    "    pred_labels = []\n",
    "    actual_labels = []\n",
    "    display_threshold = 0\n",
    "    warm_up = 10\n",
    "\n",
    "    ds = get_dataset(user_batch_size, use_cache)\n",
    "\n",
    "    ds_iter = ds.make_initializable_iterator()\n",
    "    ds_next = ds_iter.get_next()\n",
    "    ds_init_op = ds_iter.initializer\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        if use_cache:\n",
    "            sess.run(ds_init_op)\n",
    "            print('\\nCaching dataset ...')\n",
    "            start_time = time.time()\n",
    "            try:\n",
    "                while True:\n",
    "                    (validation_ds,label,_) = sess.run(ds_next)\n",
    "            except tf.errors.OutOfRangeError:\n",
    "                pass\n",
    "            print(f'Caching finished: {time.time()-start_time} sec')  \n",
    "\n",
    "        try:\n",
    "            sess.run(ds_init_op)\n",
    "            counter = 0\n",
    "            \n",
    "            total_datas = 1000\n",
    "            display_every = 100\n",
    "            display_threshold = display_every\n",
    "            \n",
    "            ipname = list(model_inf1.feed_tensors.keys())[0]\n",
    "            resname = list(model_inf1.fetch_tensors.keys())[0]\n",
    "            \n",
    "            walltime_start = time.time()\n",
    "            warmup_time = []\n",
    "            extend_time = []\n",
    "            while True:\n",
    "                sess_start = time.time()\n",
    "                (validation_ds,batch_labels,_) = sess.run(ds_next)\n",
    "                \n",
    "                model_feed_dict={ipname: validation_ds}\n",
    "                warmup_start = time.time()\n",
    "                if counter == 0:\n",
    "                    for i in range(warm_up):\n",
    "                        _ = model_inf1(model_feed_dict);                    \n",
    "                warmup_time.append(time.time() - warmup_start)\n",
    "                start_time =time.time()\n",
    "                inf1_results = model_inf1(model_feed_dict);\n",
    "                iter_times.append(time.time() - start_time)\n",
    "                \n",
    "                extend_start = time.time()\n",
    "                actual_labels.extend(label for label_list in batch_labels for label in label_list)\n",
    "                pred_labels.extend(list(np.argmax(inf1_results[resname], axis=1)))\n",
    "                extend_time.append(time.time() - extend_start)\n",
    "                \n",
    "                if counter*user_batch_size >= display_threshold:\n",
    "                    print(f'Images {counter*user_batch_size}/{total_datas}. Average i/s {np.mean(user_batch_size/np.array(iter_times[-display_every:]))}')\n",
    "                    display_threshold+=display_every\n",
    "\n",
    "                counter+=1\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            pass\n",
    "    \n",
    "    labeling_start = time.time()\n",
    "    acc_inf1 = np.sum(np.array(actual_labels) == np.array(pred_labels))/len(actual_labels)\n",
    "    iter_times = np.array(iter_times)\n",
    "    labeling_time = time.time() - labeling_start\n",
    "    \n",
    "    results = pd.DataFrame(columns = [f'inf1_compiled_batch_size_{batch_size}_compiled_cores_{num_cores}'])\n",
    "    results.loc['compiled_batch_size']     = [batch_size]\n",
    "    results.loc['user_batch_size']         = [user_batch_size]\n",
    "    results.loc['accuracy']                = [acc_inf1]\n",
    "    results.loc['prediction_time']         = [np.sum(iter_times)]\n",
    "    results.loc['warmup_time']             = [np.sum(np.array(warmup_time))]\n",
    "    results.loc['extend_time']             = [np.sum(np.array(extend_time))]\n",
    "    results.loc['labeling_time']           = [np.sum(np.array(labeling_time))]\n",
    "    results.loc['wall_time']               = [time.time() - walltime_start]\n",
    "    results.loc['images_per_sec_mean']     = [np.mean(user_batch_size / iter_times)]\n",
    "    results.loc['images_per_sec_std']      = [np.std(user_batch_size / iter_times, ddof=1)]\n",
    "    results.loc['latency_mean']            = [np.mean(iter_times) * 1000]\n",
    "    results.loc['latency_99th_percentile'] = [np.percentile(iter_times, q=99, interpolation=\"lower\") * 1000]\n",
    "    results.loc['latency_median']          = [np.median(iter_times) * 1000]\n",
    "    results.loc['latency_min']             = [np.min(iter_times) * 1000]\n",
    "    display(results.T)\n",
    "#     shutil.rmtree(neuron_saved_model_name, ignore_errors=True)\n",
    "    return results, iter_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inf1_compiled_model_dir: vgg16_inf1_saved_models/vgg16_batch_16_inf1_cores_1\n",
      "Running model vgg16_inf1_saved_models/vgg16_batch_16_inf1_cores_1, user_batch_size: 160\n",
      "\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n",
      "INFO:tensorflow:The specified SavedModel has no variables; no checkpoints were restored.\n",
      "Images 160/1000. Average i/s 704.4305637826494\n",
      "Images 320/1000. Average i/s 712.6685727191417\n",
      "Images 480/1000. Average i/s 708.8029235032435\n",
      "Images 640/1000. Average i/s 711.0405707121217\n",
      "Images 800/1000. Average i/s 710.8271270303061\n",
      "Images 960/1000. Average i/s 881.0125045554158\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>compiled_batch_size</th>\n",
       "      <th>user_batch_size</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>prediction_time</th>\n",
       "      <th>warmup_time</th>\n",
       "      <th>extend_time</th>\n",
       "      <th>labeling_time</th>\n",
       "      <th>wall_time</th>\n",
       "      <th>images_per_sec_mean</th>\n",
       "      <th>images_per_sec_std</th>\n",
       "      <th>latency_mean</th>\n",
       "      <th>latency_99th_percentile</th>\n",
       "      <th>latency_median</th>\n",
       "      <th>latency_min</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>inf1_compiled_batch_size_16_compiled_cores_1</th>\n",
       "      <td>16</td>\n",
       "      <td>160</td>\n",
       "      <td>0.845</td>\n",
       "      <td>1.43533</td>\n",
       "      <td>15.228</td>\n",
       "      <td>0.00202918</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>16.931</td>\n",
       "      <td>881.013</td>\n",
       "      <td>450.543</td>\n",
       "      <td>205.047</td>\n",
       "      <td>229.487</td>\n",
       "      <td>222.225</td>\n",
       "      <td>84.1165</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             compiled_batch_size  \\\n",
       "inf1_compiled_batch_size_16_compiled_cores_1                  16   \n",
       "\n",
       "                                             user_batch_size accuracy  \\\n",
       "inf1_compiled_batch_size_16_compiled_cores_1             160    0.845   \n",
       "\n",
       "                                             prediction_time warmup_time  \\\n",
       "inf1_compiled_batch_size_16_compiled_cores_1         1.43533      15.228   \n",
       "\n",
       "                                             extend_time labeling_time  \\\n",
       "inf1_compiled_batch_size_16_compiled_cores_1  0.00202918      0.000211   \n",
       "\n",
       "                                             wall_time images_per_sec_mean  \\\n",
       "inf1_compiled_batch_size_16_compiled_cores_1    16.931             881.013   \n",
       "\n",
       "                                             images_per_sec_std latency_mean  \\\n",
       "inf1_compiled_batch_size_16_compiled_cores_1            450.543      205.047   \n",
       "\n",
       "                                             latency_99th_percentile  \\\n",
       "inf1_compiled_batch_size_16_compiled_cores_1                 229.487   \n",
       "\n",
       "                                             latency_median latency_min  \n",
       "inf1_compiled_batch_size_16_compiled_cores_1        222.225     84.1165  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inf1_compiled_model_dir: vgg16_inf1_saved_models/vgg16_batch_16_inf1_cores_2\n",
      "Running model vgg16_inf1_saved_models/vgg16_batch_16_inf1_cores_2, user_batch_size: 160\n",
      "\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n",
      "INFO:tensorflow:The specified SavedModel has no variables; no checkpoints were restored.\n",
      "Images 160/1000. Average i/s 266.13583419025406\n",
      "Images 320/1000. Average i/s 265.90729046579344\n",
      "Images 480/1000. Average i/s 265.774202822645\n",
      "Images 640/1000. Average i/s 266.1460660428953\n",
      "Images 800/1000. Average i/s 266.25162107241687\n",
      "Images 960/1000. Average i/s 350.95369195105974\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>compiled_batch_size</th>\n",
       "      <th>user_batch_size</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>prediction_time</th>\n",
       "      <th>warmup_time</th>\n",
       "      <th>extend_time</th>\n",
       "      <th>labeling_time</th>\n",
       "      <th>wall_time</th>\n",
       "      <th>images_per_sec_mean</th>\n",
       "      <th>images_per_sec_std</th>\n",
       "      <th>latency_mean</th>\n",
       "      <th>latency_99th_percentile</th>\n",
       "      <th>latency_median</th>\n",
       "      <th>latency_min</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>inf1_compiled_batch_size_16_compiled_cores_2</th>\n",
       "      <td>16</td>\n",
       "      <td>160</td>\n",
       "      <td>0.846</td>\n",
       "      <td>3.79191</td>\n",
       "      <td>9.56145</td>\n",
       "      <td>0.00205636</td>\n",
       "      <td>0.000208378</td>\n",
       "      <td>13.6148</td>\n",
       "      <td>350.954</td>\n",
       "      <td>224.104</td>\n",
       "      <td>541.701</td>\n",
       "      <td>602.921</td>\n",
       "      <td>599.746</td>\n",
       "      <td>186.227</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             compiled_batch_size  \\\n",
       "inf1_compiled_batch_size_16_compiled_cores_2                  16   \n",
       "\n",
       "                                             user_batch_size accuracy  \\\n",
       "inf1_compiled_batch_size_16_compiled_cores_2             160    0.846   \n",
       "\n",
       "                                             prediction_time warmup_time  \\\n",
       "inf1_compiled_batch_size_16_compiled_cores_2         3.79191     9.56145   \n",
       "\n",
       "                                             extend_time labeling_time  \\\n",
       "inf1_compiled_batch_size_16_compiled_cores_2  0.00205636   0.000208378   \n",
       "\n",
       "                                             wall_time images_per_sec_mean  \\\n",
       "inf1_compiled_batch_size_16_compiled_cores_2   13.6148             350.954   \n",
       "\n",
       "                                             images_per_sec_std latency_mean  \\\n",
       "inf1_compiled_batch_size_16_compiled_cores_2            224.104      541.701   \n",
       "\n",
       "                                             latency_99th_percentile  \\\n",
       "inf1_compiled_batch_size_16_compiled_cores_2                 602.921   \n",
       "\n",
       "                                             latency_median latency_min  \n",
       "inf1_compiled_batch_size_16_compiled_cores_2        599.746     186.227  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inf1_compiled_model_dir: vgg16_inf1_saved_models/vgg16_batch_16_inf1_cores_3\n",
      "Running model vgg16_inf1_saved_models/vgg16_batch_16_inf1_cores_3, user_batch_size: 160\n",
      "\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n",
      "INFO:tensorflow:The specified SavedModel has no variables; no checkpoints were restored.\n",
      "Images 160/1000. Average i/s 269.7990099315389\n",
      "Images 320/1000. Average i/s 270.01029768818125\n",
      "Images 480/1000. Average i/s 269.52924481924794\n",
      "Images 640/1000. Average i/s 269.8826399323409\n",
      "Images 800/1000. Average i/s 270.08212762488716\n",
      "Images 960/1000. Average i/s 355.638432029497\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>compiled_batch_size</th>\n",
       "      <th>user_batch_size</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>prediction_time</th>\n",
       "      <th>warmup_time</th>\n",
       "      <th>extend_time</th>\n",
       "      <th>labeling_time</th>\n",
       "      <th>wall_time</th>\n",
       "      <th>images_per_sec_mean</th>\n",
       "      <th>images_per_sec_std</th>\n",
       "      <th>latency_mean</th>\n",
       "      <th>latency_99th_percentile</th>\n",
       "      <th>latency_median</th>\n",
       "      <th>latency_min</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>inf1_compiled_batch_size_16_compiled_cores_3</th>\n",
       "      <td>16</td>\n",
       "      <td>160</td>\n",
       "      <td>0.846</td>\n",
       "      <td>3.73866</td>\n",
       "      <td>9.61226</td>\n",
       "      <td>0.00206017</td>\n",
       "      <td>0.00196338</td>\n",
       "      <td>13.6142</td>\n",
       "      <td>355.638</td>\n",
       "      <td>226.364</td>\n",
       "      <td>534.095</td>\n",
       "      <td>594.758</td>\n",
       "      <td>591.32</td>\n",
       "      <td>184.125</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             compiled_batch_size  \\\n",
       "inf1_compiled_batch_size_16_compiled_cores_3                  16   \n",
       "\n",
       "                                             user_batch_size accuracy  \\\n",
       "inf1_compiled_batch_size_16_compiled_cores_3             160    0.846   \n",
       "\n",
       "                                             prediction_time warmup_time  \\\n",
       "inf1_compiled_batch_size_16_compiled_cores_3         3.73866     9.61226   \n",
       "\n",
       "                                             extend_time labeling_time  \\\n",
       "inf1_compiled_batch_size_16_compiled_cores_3  0.00206017    0.00196338   \n",
       "\n",
       "                                             wall_time images_per_sec_mean  \\\n",
       "inf1_compiled_batch_size_16_compiled_cores_3   13.6142             355.638   \n",
       "\n",
       "                                             images_per_sec_std latency_mean  \\\n",
       "inf1_compiled_batch_size_16_compiled_cores_3            226.364      534.095   \n",
       "\n",
       "                                             latency_99th_percentile  \\\n",
       "inf1_compiled_batch_size_16_compiled_cores_3                 594.758   \n",
       "\n",
       "                                             latency_median latency_min  \n",
       "inf1_compiled_batch_size_16_compiled_cores_3         591.32     184.125  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inf1_compiled_model_dir: vgg16_inf1_saved_models/vgg16_batch_16_inf1_cores_4\n",
      "Running model vgg16_inf1_saved_models/vgg16_batch_16_inf1_cores_4, user_batch_size: 160\n",
      "\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n",
      "INFO:tensorflow:The specified SavedModel has no variables; no checkpoints were restored.\n",
      "Images 160/1000. Average i/s 398.6086335602753\n",
      "Images 320/1000. Average i/s 397.86416720222195\n",
      "Images 480/1000. Average i/s 397.86806069397755\n",
      "Images 640/1000. Average i/s 398.5991400751215\n",
      "Images 800/1000. Average i/s 399.04987006285637\n",
      "Images 960/1000. Average i/s 499.91757485770984\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>compiled_batch_size</th>\n",
       "      <th>user_batch_size</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>prediction_time</th>\n",
       "      <th>warmup_time</th>\n",
       "      <th>extend_time</th>\n",
       "      <th>labeling_time</th>\n",
       "      <th>wall_time</th>\n",
       "      <th>images_per_sec_mean</th>\n",
       "      <th>images_per_sec_std</th>\n",
       "      <th>latency_mean</th>\n",
       "      <th>latency_99th_percentile</th>\n",
       "      <th>latency_median</th>\n",
       "      <th>latency_min</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>inf1_compiled_batch_size_16_compiled_cores_4</th>\n",
       "      <td>16</td>\n",
       "      <td>160</td>\n",
       "      <td>0.846</td>\n",
       "      <td>2.55056</td>\n",
       "      <td>7.79514</td>\n",
       "      <td>0.00204444</td>\n",
       "      <td>0.000212193</td>\n",
       "      <td>10.6176</td>\n",
       "      <td>499.918</td>\n",
       "      <td>266.879</td>\n",
       "      <td>364.366</td>\n",
       "      <td>403.24</td>\n",
       "      <td>399.569</td>\n",
       "      <td>144.78</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             compiled_batch_size  \\\n",
       "inf1_compiled_batch_size_16_compiled_cores_4                  16   \n",
       "\n",
       "                                             user_batch_size accuracy  \\\n",
       "inf1_compiled_batch_size_16_compiled_cores_4             160    0.846   \n",
       "\n",
       "                                             prediction_time warmup_time  \\\n",
       "inf1_compiled_batch_size_16_compiled_cores_4         2.55056     7.79514   \n",
       "\n",
       "                                             extend_time labeling_time  \\\n",
       "inf1_compiled_batch_size_16_compiled_cores_4  0.00204444   0.000212193   \n",
       "\n",
       "                                             wall_time images_per_sec_mean  \\\n",
       "inf1_compiled_batch_size_16_compiled_cores_4   10.6176             499.918   \n",
       "\n",
       "                                             images_per_sec_std latency_mean  \\\n",
       "inf1_compiled_batch_size_16_compiled_cores_4            266.879      364.366   \n",
       "\n",
       "                                             latency_99th_percentile  \\\n",
       "inf1_compiled_batch_size_16_compiled_cores_4                  403.24   \n",
       "\n",
       "                                             latency_median latency_min  \n",
       "inf1_compiled_batch_size_16_compiled_cores_4        399.569      144.78  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>inf1_compiled_batch_size_16_compiled_cores_1</th>\n",
       "      <th>inf1_compiled_batch_size_16_compiled_cores_2</th>\n",
       "      <th>inf1_compiled_batch_size_16_compiled_cores_3</th>\n",
       "      <th>inf1_compiled_batch_size_16_compiled_cores_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>compiled_batch_size</th>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_batch_size</th>\n",
       "      <td>160</td>\n",
       "      <td>160</td>\n",
       "      <td>160</td>\n",
       "      <td>160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.845</td>\n",
       "      <td>0.846</td>\n",
       "      <td>0.846</td>\n",
       "      <td>0.846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prediction_time</th>\n",
       "      <td>1.43533</td>\n",
       "      <td>3.79191</td>\n",
       "      <td>3.73866</td>\n",
       "      <td>2.55056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>warmup_time</th>\n",
       "      <td>15.228</td>\n",
       "      <td>9.56145</td>\n",
       "      <td>9.61226</td>\n",
       "      <td>7.79514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>extend_time</th>\n",
       "      <td>0.00202918</td>\n",
       "      <td>0.00205636</td>\n",
       "      <td>0.00206017</td>\n",
       "      <td>0.00204444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>labeling_time</th>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.000208378</td>\n",
       "      <td>0.00196338</td>\n",
       "      <td>0.000212193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wall_time</th>\n",
       "      <td>16.931</td>\n",
       "      <td>13.6148</td>\n",
       "      <td>13.6142</td>\n",
       "      <td>10.6176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>images_per_sec_mean</th>\n",
       "      <td>881.013</td>\n",
       "      <td>350.954</td>\n",
       "      <td>355.638</td>\n",
       "      <td>499.918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>images_per_sec_std</th>\n",
       "      <td>450.543</td>\n",
       "      <td>224.104</td>\n",
       "      <td>226.364</td>\n",
       "      <td>266.879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>latency_mean</th>\n",
       "      <td>205.047</td>\n",
       "      <td>541.701</td>\n",
       "      <td>534.095</td>\n",
       "      <td>364.366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>latency_99th_percentile</th>\n",
       "      <td>229.487</td>\n",
       "      <td>602.921</td>\n",
       "      <td>594.758</td>\n",
       "      <td>403.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>latency_median</th>\n",
       "      <td>222.225</td>\n",
       "      <td>599.746</td>\n",
       "      <td>591.32</td>\n",
       "      <td>399.569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>latency_min</th>\n",
       "      <td>84.1165</td>\n",
       "      <td>186.227</td>\n",
       "      <td>184.125</td>\n",
       "      <td>144.78</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        inf1_compiled_batch_size_16_compiled_cores_1  \\\n",
       "compiled_batch_size                                               16   \n",
       "user_batch_size                                                  160   \n",
       "accuracy                                                       0.845   \n",
       "prediction_time                                              1.43533   \n",
       "warmup_time                                                   15.228   \n",
       "extend_time                                               0.00202918   \n",
       "labeling_time                                               0.000211   \n",
       "wall_time                                                     16.931   \n",
       "images_per_sec_mean                                          881.013   \n",
       "images_per_sec_std                                           450.543   \n",
       "latency_mean                                                 205.047   \n",
       "latency_99th_percentile                                      229.487   \n",
       "latency_median                                               222.225   \n",
       "latency_min                                                  84.1165   \n",
       "\n",
       "                        inf1_compiled_batch_size_16_compiled_cores_2  \\\n",
       "compiled_batch_size                                               16   \n",
       "user_batch_size                                                  160   \n",
       "accuracy                                                       0.846   \n",
       "prediction_time                                              3.79191   \n",
       "warmup_time                                                  9.56145   \n",
       "extend_time                                               0.00205636   \n",
       "labeling_time                                            0.000208378   \n",
       "wall_time                                                    13.6148   \n",
       "images_per_sec_mean                                          350.954   \n",
       "images_per_sec_std                                           224.104   \n",
       "latency_mean                                                 541.701   \n",
       "latency_99th_percentile                                      602.921   \n",
       "latency_median                                               599.746   \n",
       "latency_min                                                  186.227   \n",
       "\n",
       "                        inf1_compiled_batch_size_16_compiled_cores_3  \\\n",
       "compiled_batch_size                                               16   \n",
       "user_batch_size                                                  160   \n",
       "accuracy                                                       0.846   \n",
       "prediction_time                                              3.73866   \n",
       "warmup_time                                                  9.61226   \n",
       "extend_time                                               0.00206017   \n",
       "labeling_time                                             0.00196338   \n",
       "wall_time                                                    13.6142   \n",
       "images_per_sec_mean                                          355.638   \n",
       "images_per_sec_std                                           226.364   \n",
       "latency_mean                                                 534.095   \n",
       "latency_99th_percentile                                      594.758   \n",
       "latency_median                                                591.32   \n",
       "latency_min                                                  184.125   \n",
       "\n",
       "                        inf1_compiled_batch_size_16_compiled_cores_4  \n",
       "compiled_batch_size                                               16  \n",
       "user_batch_size                                                  160  \n",
       "accuracy                                                       0.846  \n",
       "prediction_time                                              2.55056  \n",
       "warmup_time                                                  7.79514  \n",
       "extend_time                                               0.00204444  \n",
       "labeling_time                                            0.000212193  \n",
       "wall_time                                                    10.6176  \n",
       "images_per_sec_mean                                          499.918  \n",
       "images_per_sec_std                                           266.879  \n",
       "latency_mean                                                 364.366  \n",
       "latency_99th_percentile                                       403.24  \n",
       "latency_median                                               399.569  \n",
       "latency_min                                                   144.78  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "inf1_model_dir = f'{model_type}_inf1_saved_models'\n",
    "saved_model_dir = f'{model_type}_saved_model'\n",
    "\n",
    "\n",
    "# testing batch size\n",
    "batch_list = [16]\n",
    "num_of_cores = [1,2,3,4]\n",
    "\n",
    "inf1_model_dir = f'{model_type}_inf1_saved_models'\n",
    "\n",
    "for batch_size in batch_list:\n",
    "    iter_ds = pd.DataFrame()\n",
    "    results = pd.DataFrame()\n",
    "    for num_cores in num_of_cores:\n",
    "        opt ={'batch_size': batch_size, 'num_cores': num_of_cores}\n",
    "        compiled_model_dir = f'{model_type}_batch_{batch_size}_inf1_cores_{num_cores}'\n",
    "        inf1_compiled_model_dir = os.path.join(inf1_model_dir, compiled_model_dir)\n",
    "\n",
    "        print(f'inf1_compiled_model_dir: {inf1_compiled_model_dir}')\n",
    "        col_name = lambda opt: f'inf1_{batch_size}_multicores_{num_cores}'\n",
    "\n",
    "        res, iter_times = inf1_predict_benchmark_single_threaded(inf1_compiled_model_dir,\n",
    "                                                                         batch_size = batch_size,\n",
    "                                                                         user_batch_size = batch_size*10,\n",
    "                                                                         num_cores = num_cores,\n",
    "                                                                         use_cache=False, \n",
    "                                                                         warm_up=10)\n",
    "\n",
    "        iter_ds = pd.concat([iter_ds, pd.DataFrame(iter_times, columns=[col_name(opt)])], axis=1)\n",
    "        results = pd.concat([results, res], axis=1)\n",
    "\n",
    "    display(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aws_neuron_tensorflow_p36",
   "language": "python",
   "name": "aws_neuron_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
