{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AWS Inferentia inference on Amazon EC2 Inf1 instance\n",
    "This example demonstrates AWS Inferentia inference with TensorFlow and AWS Neuron SDK compiler and runtime\n",
    "\n",
    "This example was tested on Amazon EC2 `inf1.xlarge` the following AWS Deep Learning AMI: \n",
    "`Deep Learning AMI (Ubuntu 18.04) Version 35.0`\n",
    "\n",
    "Run this notebook using the following conda environment:\n",
    "`aws_neuron_tensorflow_p36`\n",
    "\n",
    "Prepare your imagenet validation TFRecord files using the following helper script:\n",
    "https://github.com/tensorflow/models/blob/archive/research/inception/inception/data/download_and_preprocess_imagenet.sh\n",
    "\n",
    "Save it to `/home/ubuntu/datasets/` or update the dataset location in the `get_dataset()` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install matplotlib pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n"
     ]
    }
   ],
   "source": [
    "!/opt/aws/neuron/bin/neuron-cli reset\n",
    "import os\n",
    "import time\n",
    "import shutil\n",
    "import json\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow.neuron as tfn\n",
    "import tensorflow.compat.v1.keras as keras\n",
    "from tensorflow.keras.applications import ( \n",
    "    xception,\n",
    "    vgg16,\n",
    "    vgg19,\n",
    "    resnet,\n",
    "    resnet50,\n",
    "    resnet_v2,\n",
    "    inception_v3,\n",
    "    inception_resnet_v2,\n",
    "    mobilenet,\n",
    "    densenet,\n",
    "    nasnet,\n",
    "    mobilenet_v2\n",
    ")\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from concurrent import futures\n",
    "from itertools import compress\n",
    "\n",
    "models = {\n",
    "    'xception':xception,\n",
    "    'vgg16':vgg16,\n",
    "    'vgg19':vgg19,\n",
    "    'resnet50':resnet50,\n",
    "    'resnet101':resnet,\n",
    "    'resnet152':resnet,\n",
    "    'resnet50_v2':resnet_v2,\n",
    "    'resnet101_v2':resnet_v2,\n",
    "    'resnet152_v2':resnet_v2,\n",
    "#     'resnext50':resnext,\n",
    "#     'resnext101':resnext,\n",
    "    'inception_v3':inception_v3,\n",
    "    'inception_resnet_v2':inception_resnet_v2,\n",
    "    'mobilenet':mobilenet,\n",
    "    'densenet121':densenet,\n",
    "    'densenet169':densenet,\n",
    "    'densenet201':densenet,\n",
    "    'nasnetlarge':nasnet,\n",
    "    'nasnetmobile':nasnet,\n",
    "    'mobilenet_v2':mobilenet_v2\n",
    "}\n",
    "\n",
    "models_detail = {\n",
    "#     'xception':xception.Xception(weights='imagenet',include_top=False),\n",
    "#     'vgg16':vgg16.VGG16(weights='imagenet'),\n",
    "#     'vgg19':vgg19.VGG19(weights='imagenet'),\n",
    "#     'resnet50':resnet.ResNet50(weights='imagenet'),\n",
    "#     'resnet101':resnet.ResNet101(weights='imagenet'),\n",
    "#     'resnet152':resnet.ResNet152(weights='imagenet'),\n",
    "#     'resnet50_v2':resnet_v2.ResNet50V2(weights='imagenet'),\n",
    "#     'resnet101_v2':resnet_v2.ResNet101V2(weights='imagenet'),\n",
    "#     'resnet152_v2':resnet_v2.ResNet152V2(weights='imagenet'),\n",
    "#     'resnext50':resnext.ResNeXt50(weights='imagenet'),\n",
    "#     'resnext101':resnext.ResNeXt101(weights='imagenet'),\n",
    "#     'inception_v3':inception_v3.InceptionV3(weights='imagenet',include_top=False),\n",
    "#     'inception_resnet_v2':inception_resnet_v2.InceptionResNetV2(weights='imagenet'),\n",
    "#     'mobilenet':mobilenet.MobileNet(weights='imagenet'),\n",
    "#     'densenet121':densenet.DenseNet121(weights='imagenet'),\n",
    "#     'densenet169':densenet.DenseNet169(weights='imagenet'),\n",
    "#     'densenet201':densenet.DenseNet201(weights='imagenet'),\n",
    "#     'nasnetlarge':nasnet.NASNetLarge(weights='imagenet'),\n",
    "#     'nasnetmobile':nasnet.NASNetMobile(weights='imagenet'),\n",
    "#     'mobilenet_v2':mobilenet_v2.MobileNetV2(weights='imagenet')\n",
    "}\n",
    "\n",
    "print('test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resnet50 FP32 saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Export SavedModel\n",
    "# model_type = 'resnet50'\n",
    "\n",
    "# saved_model_dir = f'{model_type}_saved_model'\n",
    "# shutil.rmtree(saved_model_dir, ignore_errors=True)\n",
    "\n",
    "keras.backend.set_learning_phase(0)\n",
    "# model = ResNet50(weights='imagenet')\n",
    "# tf.saved_model.simple_save(session = keras.backend.get_session(),\n",
    "#                            export_dir = saved_model_dir,\n",
    "#                            inputs = {'input_1:0': model.inputs[0]},\n",
    "#                            outputs = {'probs/Softmax:0': model.outputs[0]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile models with different batch sizes and cores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_inf1_model(saved_model_dir, inf1_model_dir, batch_size=1, num_cores=1, use_static_weights=False):\n",
    "    print(f'-----------batch size: {batch_size}, num cores: {num_cores}----------')\n",
    "    print('Compiling...')\n",
    "    \n",
    "    compiled_model_dir = f'{model_type}_batch_{batch_size}_inf1_cores_{num_cores}'\n",
    "    inf1_compiled_model_dir = os.path.join(inf1_model_dir, compiled_model_dir)\n",
    "    shutil.rmtree(inf1_compiled_model_dir, ignore_errors=True)\n",
    "\n",
    "    example_input = np.zeros([batch_size,224,224,3], dtype='float32')\n",
    "\n",
    "    compiler_args = ['--verbose','1', '--neuroncore-pipeline-cores', str(num_cores)]\n",
    "    if use_static_weights:\n",
    "        compiler_args.append('--static-weights')\n",
    "    \n",
    "    start_time = time.time()\n",
    "    compiled_res = tfn.saved_model.compile(model_dir = saved_model_dir,\n",
    "                            model_feed_dict={'input_1:0': example_input},\n",
    "                            new_model_dir = inf1_compiled_model_dir,\n",
    "                            dynamic_batch_size=True,\n",
    "                            compiler_args = compiler_args)\n",
    "    print(f'Compile time: {time.time() - start_time}')\n",
    "    \n",
    "    compile_success = False\n",
    "    perc_on_inf = compiled_res['OnNeuronRatio'] * 100\n",
    "    if perc_on_inf > 50:\n",
    "        compile_success = True\n",
    "            \n",
    "    print(inf1_compiled_model_dir)\n",
    "    print(compiled_res)\n",
    "    print('----------- Done! ----------- \\n')\n",
    "    \n",
    "    return compile_success"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use `tf.data` to read ImageNet validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deserialize_image_record(record):\n",
    "    feature_map = {'image/encoded': tf.io.FixedLenFeature([], tf.string, ''),\n",
    "                  'image/class/label': tf.io.FixedLenFeature([1], tf.int64, -1),\n",
    "                  'image/class/text': tf.io.FixedLenFeature([], tf.string, '')}\n",
    "    obj = tf.io.parse_single_example(serialized=record, features=feature_map)\n",
    "    imgdata = obj['image/encoded']\n",
    "    label = tf.cast(obj['image/class/label'], tf.int32)   \n",
    "    label_text = tf.cast(obj['image/class/text'], tf.string)   \n",
    "    return imgdata, label, label_text\n",
    "\n",
    "def val_preprocessing(record):\n",
    "    imgdata, label, label_text = deserialize_image_record(record)\n",
    "    label -= 1\n",
    "    image = tf.io.decode_jpeg(imgdata, channels=3, \n",
    "                              fancy_upscaling=False, \n",
    "                              dct_method='INTEGER_FAST')\n",
    "\n",
    "    shape = tf.shape(image)\n",
    "    height = tf.cast(shape[0], tf.float32)\n",
    "    width = tf.cast(shape[1], tf.float32)\n",
    "    side = tf.cast(tf.convert_to_tensor(256, dtype=tf.int32), tf.float32)\n",
    "\n",
    "    scale = tf.cond(tf.greater(height, width),\n",
    "                  lambda: side / width,\n",
    "                  lambda: side / height)\n",
    "    \n",
    "    new_height = tf.cast(tf.math.rint(height * scale), tf.int32)\n",
    "    new_width = tf.cast(tf.math.rint(width * scale), tf.int32)\n",
    "    \n",
    "    image = tf.image.resize(image, [new_height, new_width], method='bicubic')\n",
    "    image = tf.image.resize_with_crop_or_pad(image, 224, 224)\n",
    "    \n",
    "    image = models[model_type].preprocess_input(image)\n",
    "    \n",
    "    return image, label, label_text\n",
    "\n",
    "def get_dataset(batch_size, use_cache=False):\n",
    "    data_dir = '/home/ubuntu/datasets/images-1000/*'\n",
    "    files = tf.io.gfile.glob(os.path.join(data_dir))\n",
    "    dataset = tf.data.TFRecordDataset(files)\n",
    "    \n",
    "    dataset = dataset.map(map_func=val_preprocessing, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    dataset = dataset.batch(batch_size=batch_size)\n",
    "    dataset = dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "    dataset = dataset.repeat(count=1)\n",
    "    \n",
    "    if use_cache:\n",
    "        shutil.rmtree('tfdatacache', ignore_errors=True)\n",
    "        os.mkdir('tfdatacache')\n",
    "        dataset = dataset.cache(f'./tfdatacache/imagenet_val')\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single AWS Inferentia chip execution\n",
    "* Single core compiled models with automatic data parallel model upto 4 cores\n",
    "* Multi-core compiled models for pipeline execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def inf1_predict_benchmark_single_threaded(neuron_saved_model_name, batch_size, user_batch_size, num_cores, use_cache=False, warm_up=10):\n",
    "    print(f'Running model {neuron_saved_model_name}, user_batch_size: {user_batch_size}\\n')\n",
    "\n",
    "    model_inf1 = tf.contrib.predictor.from_saved_model(neuron_saved_model_name)\n",
    "\n",
    "    first_iter_time = 0\n",
    "    iter_times = []\n",
    "    pred_labels = []\n",
    "    actual_labels = []\n",
    "    display_threshold = 0\n",
    "    warm_up = 10\n",
    "\n",
    "    ds = get_dataset(user_batch_size, use_cache)\n",
    "\n",
    "    ds_iter = ds.make_initializable_iterator()\n",
    "    ds_next = ds_iter.get_next()\n",
    "    ds_init_op = ds_iter.initializer\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        if use_cache:\n",
    "            sess.run(ds_init_op)\n",
    "            print('\\nCaching dataset ...')\n",
    "            start_time = time.time()\n",
    "            try:\n",
    "                while True:\n",
    "                    (validation_ds,label,_) = sess.run(ds_next)\n",
    "            except tf.errors.OutOfRangeError:\n",
    "                pass\n",
    "            print(f'Caching finished: {time.time()-start_time} sec')  \n",
    "\n",
    "        try:\n",
    "            sess.run(ds_init_op)\n",
    "            counter = 0\n",
    "            \n",
    "            total_datas = 1000\n",
    "            display_every = 100\n",
    "            display_threshold = display_every\n",
    "            \n",
    "            ipname = list(model_inf1.feed_tensors.keys())[0]\n",
    "            resname = list(model_inf1.fetch_tensors.keys())[0]\n",
    "            \n",
    "            walltime_start = time.time()\n",
    "            warmup_time = []\n",
    "            extend_time = []\n",
    "            while True:\n",
    "                sess_start = time.time()\n",
    "                (validation_ds,batch_labels,_) = sess.run(ds_next)\n",
    "                \n",
    "                model_feed_dict={ipname: validation_ds}\n",
    "#                 warmup_start = time.time()\n",
    "#                 if counter == 0:\n",
    "#                     for i in range(warm_up):\n",
    "#                         _ = model_inf1(model_feed_dict);                    \n",
    "#                 warmup_time.append(time.time() - warmup_start)\n",
    "                start_time =time.time()\n",
    "                inf1_results = model_inf1(model_feed_dict);\n",
    "                if counter == 0:\n",
    "                    first_iter_time = time.time() - start_time\n",
    "                else:\n",
    "                    iter_times.append(time.time() - start_time)\n",
    "                \n",
    "                actual_labels.extend(label for label_list in batch_labels for label in label_list)\n",
    "                pred_labels.extend(list(np.argmax(inf1_results[resname], axis=1)))\n",
    "                \n",
    "                if counter*user_batch_size >= display_threshold:\n",
    "                    print(f'Images {counter*user_batch_size}/{total_datas}. Average i/s {np.mean(user_batch_size/np.array(iter_times[-display_every:]))}')\n",
    "                    display_threshold+=display_every\n",
    "\n",
    "                counter+=1\n",
    "                \n",
    "        except tf.errors.OutOfRangeError:\n",
    "            pass\n",
    "    \n",
    "    acc_inf1 = np.sum(np.array(actual_labels) == np.array(pred_labels))/len(actual_labels)\n",
    "    iter_times = np.array(iter_times)\n",
    "    \n",
    "    results = pd.DataFrame(columns = [f'inf1_compiled_batch_size_{batch_size}_compiled_cores_{num_cores}'])\n",
    "    results.loc['compiled_batch_size']     = [batch_size]\n",
    "    results.loc['user_batch_size']         = [user_batch_size]\n",
    "    results.loc['accuracy']                = [acc_inf1]\n",
    "    results.loc['first_prediction_time']   = [first_iter_time]\n",
    "    results.loc['average_prediction_time'] = [np.mean(iter_times)]\n",
    "    results.loc['wall_time']               = [time.time() - walltime_start]\n",
    "    results.loc['images_per_sec_mean']     = [np.mean(user_batch_size / iter_times)]\n",
    "    results.loc['images_per_sec_std']      = [np.std(user_batch_size / iter_times, ddof=1)]\n",
    "    results.loc['latency_mean']            = [np.mean(iter_times) * 1000]\n",
    "    results.loc['latency_99th_percentile'] = [np.percentile(iter_times, q=99, interpolation=\"lower\") * 1000]\n",
    "    results.loc['latency_median']          = [np.median(iter_times) * 1000]\n",
    "    results.loc['latency_min']             = [np.min(iter_times) * 1000]\n",
    "    display(results.T)\n",
    "#     shutil.rmtree(neuron_saved_model_name, ignore_errors=True)\n",
    "    return results, iter_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inf1_compiled_model_dir: resnet50dboff_inf1_saved_models/resnet50_batch_1_inf1_cores_1\n",
      "Running model resnet50dboff_inf1_saved_models/resnet50_batch_1_inf1_cores_1, user_batch_size: 1\n",
      "\n",
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/aws_neuron_tensorflow_p36/lib/python3.6/site-packages/tensorflow_core/contrib/predictor/saved_model_predictor.py:153: load (from tensorflow.python.saved_model.loader_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.loader.load or tf.compat.v1.saved_model.load. There will be a new function for importing SavedModels in Tensorflow 2.0.\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n",
      "INFO:tensorflow:The specified SavedModel has no variables; no checkpoints were restored.\n",
      "WARNING:tensorflow:From <ipython-input-6-9dc9f712a4bd>:15: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.\n",
      "Images 100/1000. Average i/s 237.69561840515905\n",
      "Images 200/1000. Average i/s 239.7728964342552\n",
      "Images 300/1000. Average i/s 240.43209709687116\n",
      "Images 400/1000. Average i/s 246.25625435678063\n",
      "Images 500/1000. Average i/s 233.0833453429273\n",
      "Images 600/1000. Average i/s 234.9381104296699\n",
      "Images 700/1000. Average i/s 237.38302318556853\n",
      "Images 800/1000. Average i/s 236.76262609537605\n",
      "Images 900/1000. Average i/s 237.3312701514734\n",
      "Images 1000/1000. Average i/s 234.32462145532972\n",
      "Images 1100/1000. Average i/s 227.8735154130188\n",
      "Images 1200/1000. Average i/s 232.69331042989958\n",
      "Images 1300/1000. Average i/s 223.87643446518186\n",
      "Images 1400/1000. Average i/s 235.79444930470038\n",
      "Images 1500/1000. Average i/s 233.78377347907207\n",
      "Images 1600/1000. Average i/s 240.0405664317337\n",
      "Images 1700/1000. Average i/s 231.3144926553328\n",
      "Images 1800/1000. Average i/s 236.14764835858324\n",
      "Images 1900/1000. Average i/s 226.50966531072902\n",
      "Images 2000/1000. Average i/s 227.43490222185392\n",
      "Images 2100/1000. Average i/s 230.028367005923\n",
      "Images 2200/1000. Average i/s 232.74649812450687\n",
      "Images 2300/1000. Average i/s 226.42569359896555\n",
      "Images 2400/1000. Average i/s 218.9219963855224\n",
      "Images 2500/1000. Average i/s 221.04184820623502\n",
      "Images 2600/1000. Average i/s 223.81345110047252\n",
      "Images 2700/1000. Average i/s 226.13252540625786\n",
      "Images 2800/1000. Average i/s 218.08413864586103\n",
      "Images 2900/1000. Average i/s 210.89428421080146\n",
      "Images 3000/1000. Average i/s 216.87056197851172\n",
      "Images 3100/1000. Average i/s 217.8025909513752\n",
      "Images 3200/1000. Average i/s 207.78385721365245\n",
      "Images 3300/1000. Average i/s 212.2150630165878\n",
      "Images 3400/1000. Average i/s 213.93259258079763\n",
      "Images 3500/1000. Average i/s 209.79734627388868\n",
      "Images 3600/1000. Average i/s 208.26893978791975\n",
      "Images 3700/1000. Average i/s 201.12641607569066\n",
      "Images 3800/1000. Average i/s 203.64481512891675\n",
      "Images 3900/1000. Average i/s 196.64174837229285\n",
      "Images 4000/1000. Average i/s 197.57154452631661\n",
      "Images 4100/1000. Average i/s 197.43333897982538\n",
      "Images 4200/1000. Average i/s 188.6350802005578\n",
      "Images 4300/1000. Average i/s 187.35582900486224\n",
      "Images 4400/1000. Average i/s 186.66556368650177\n",
      "Images 4500/1000. Average i/s 178.46201766974363\n",
      "Images 4600/1000. Average i/s 168.9858646953587\n",
      "Images 4700/1000. Average i/s 179.4942399749516\n",
      "Images 4800/1000. Average i/s 175.5619553649164\n",
      "Images 4900/1000. Average i/s 174.44141074003332\n",
      "Images 5000/1000. Average i/s 192.96539021831887\n",
      "Images 5100/1000. Average i/s 178.56396483650383\n",
      "Images 5200/1000. Average i/s 202.8662124313871\n",
      "Images 5300/1000. Average i/s 289.77170949553846\n",
      "Images 5400/1000. Average i/s 291.41268819968866\n",
      "Images 5500/1000. Average i/s 292.75200794802856\n",
      "Images 5600/1000. Average i/s 292.36407084902584\n",
      "Images 5700/1000. Average i/s 291.84324562928833\n",
      "Images 5800/1000. Average i/s 292.06781401957494\n",
      "Images 5900/1000. Average i/s 289.8732670005078\n",
      "Images 6000/1000. Average i/s 291.23370929808056\n",
      "Images 6100/1000. Average i/s 291.9057327430146\n",
      "Images 6200/1000. Average i/s 290.76248903025254\n",
      "Images 6300/1000. Average i/s 291.0881392376449\n",
      "Images 6400/1000. Average i/s 290.877458163739\n",
      "Images 6500/1000. Average i/s 291.91232719391434\n",
      "Images 6600/1000. Average i/s 291.1200730237917\n",
      "Images 6700/1000. Average i/s 290.62297835802553\n",
      "Images 6800/1000. Average i/s 290.04698223547643\n",
      "Images 6900/1000. Average i/s 289.95688352461787\n",
      "Images 7000/1000. Average i/s 289.95219263619856\n",
      "Images 7100/1000. Average i/s 288.9361049607942\n",
      "Images 7200/1000. Average i/s 289.6350748501282\n",
      "Images 7300/1000. Average i/s 288.6012864532075\n",
      "Images 7400/1000. Average i/s 288.7111787492549\n",
      "Images 7500/1000. Average i/s 289.76631848056445\n",
      "Images 7600/1000. Average i/s 289.6929557209506\n",
      "Images 7700/1000. Average i/s 290.7735799408589\n",
      "Images 7800/1000. Average i/s 291.1868448317718\n",
      "Images 7900/1000. Average i/s 290.0544720488749\n",
      "Images 8000/1000. Average i/s 288.9980147654117\n",
      "Images 8100/1000. Average i/s 289.6067028818151\n",
      "Images 8200/1000. Average i/s 289.35783977246246\n",
      "Images 8300/1000. Average i/s 290.19998667196177\n",
      "Images 8400/1000. Average i/s 290.1410503600458\n",
      "Images 8500/1000. Average i/s 290.1437624495739\n",
      "Images 8600/1000. Average i/s 289.79246271039943\n",
      "Images 8700/1000. Average i/s 290.5374458243451\n",
      "Images 8800/1000. Average i/s 290.4095882520524\n",
      "Images 8900/1000. Average i/s 290.56631584455573\n",
      "Images 9000/1000. Average i/s 289.7024542881185\n",
      "Images 9100/1000. Average i/s 290.0406762563059\n",
      "Images 9200/1000. Average i/s 290.29766518861595\n",
      "Images 9300/1000. Average i/s 290.2711093871271\n",
      "Images 9400/1000. Average i/s 290.7229809975356\n",
      "Images 9500/1000. Average i/s 291.03995248772196\n",
      "Images 9600/1000. Average i/s 291.023747885173\n",
      "Images 9700/1000. Average i/s 290.82828465590586\n",
      "Images 9800/1000. Average i/s 290.5166071014968\n",
      "Images 9900/1000. Average i/s 289.65659919450883\n",
      "Images 10000/1000. Average i/s 290.12160407105233\n",
      "Images 10100/1000. Average i/s 289.66408900485055\n",
      "Images 10200/1000. Average i/s 289.8170031145349\n",
      "Images 10300/1000. Average i/s 289.82950655829706\n",
      "Images 10400/1000. Average i/s 289.81271604501717\n",
      "Images 10500/1000. Average i/s 290.10262505238256\n",
      "Images 10600/1000. Average i/s 290.106944328636\n",
      "Images 10700/1000. Average i/s 290.00717670759207\n",
      "Images 10800/1000. Average i/s 290.7825315878349\n",
      "Images 10900/1000. Average i/s 290.7389811339201\n",
      "Images 11000/1000. Average i/s 290.84631444348275\n",
      "Images 11100/1000. Average i/s 290.73445605526246\n",
      "Images 11200/1000. Average i/s 291.12780733579604\n",
      "Images 11300/1000. Average i/s 291.02412867322744\n",
      "Images 11400/1000. Average i/s 291.1081803852321\n",
      "Images 11500/1000. Average i/s 290.2657424201362\n",
      "Images 11600/1000. Average i/s 290.707014063745\n",
      "Images 11700/1000. Average i/s 291.2402473206135\n",
      "Images 11800/1000. Average i/s 290.8349297297751\n",
      "Images 11900/1000. Average i/s 290.65334291007775\n",
      "Images 12000/1000. Average i/s 290.8597205671413\n",
      "Images 12100/1000. Average i/s 291.35610718833317\n",
      "Images 12200/1000. Average i/s 290.9059859684434\n",
      "Images 12300/1000. Average i/s 290.4207259556141\n",
      "Images 12400/1000. Average i/s 290.29541696995597\n",
      "Images 12500/1000. Average i/s 290.2913210566681\n",
      "Images 12600/1000. Average i/s 290.2958009736899\n",
      "Images 12700/1000. Average i/s 290.53707594832304\n",
      "Images 12800/1000. Average i/s 290.4814000967558\n",
      "Images 12900/1000. Average i/s 290.3908973511016\n",
      "Images 13000/1000. Average i/s 290.2661989104496\n",
      "Images 13100/1000. Average i/s 290.19297128126146\n",
      "Images 13200/1000. Average i/s 289.99720078364226\n",
      "Images 13300/1000. Average i/s 290.0710252343961\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images 13400/1000. Average i/s 290.6895820610194\n",
      "Images 13500/1000. Average i/s 290.3874493679685\n",
      "Images 13600/1000. Average i/s 290.60682902062956\n",
      "Images 13700/1000. Average i/s 290.7158276788679\n",
      "Images 13800/1000. Average i/s 290.5966809765259\n",
      "Images 13900/1000. Average i/s 290.63766815991147\n",
      "Images 14000/1000. Average i/s 290.87670362785843\n",
      "Images 14100/1000. Average i/s 290.9989689620771\n"
     ]
    }
   ],
   "source": [
    "model_type = 'resnet50'\n",
    "# https://github.com/tensorflow/tensorflow/issues/29931\n",
    "temp = tf.zeros([8, 224, 224, 3])\n",
    "_ = models[model_type].preprocess_input(temp)\n",
    "\n",
    "# testing batch size\n",
    "batch_list = [1,2,4,8,16,32,64]\n",
    "num_of_cores = [1]\n",
    "user_batchs = [1,2,4,8,16,32,64]\n",
    "inf1_model_dir = f'{model_type}_inf1_saved_models'\n",
    "\n",
    "for user_batch in user_batchs:\n",
    "    iter_ds = pd.DataFrame()\n",
    "    results = pd.DataFrame()\n",
    "    for batch_size in batch_list:\n",
    "        for num_cores in num_of_cores:\n",
    "            opt ={'batch_size': batch_size, 'num_cores': num_of_cores}\n",
    "            compiled_model_dir = f'{model_type}_batch_{batch_size}_inf1_cores_{num_cores}'\n",
    "            inf1_compiled_model_dir = os.path.join(inf1_model_dir, compiled_model_dir)\n",
    "\n",
    "            print(f'inf1_compiled_model_dir: {inf1_compiled_model_dir}')\n",
    "            col_name = lambda opt: f'inf1_{batch_size}_multicores_{num_cores}'\n",
    "\n",
    "            res, iter_times = inf1_predict_benchmark_single_threaded(inf1_compiled_model_dir,\n",
    "                                                                             batch_size = batch_size,\n",
    "                                                                             user_batch_size = batch_size*user_batch,\n",
    "                                                                             num_cores = num_cores,\n",
    "                                                                             use_cache=False, \n",
    "                                                                             warm_up=10)\n",
    "\n",
    "        iter_ds = pd.concat([iter_ds, pd.DataFrame(iter_times, columns=[col_name(opt)])], axis=1)\n",
    "        results = pd.concat([results, res], axis=1)\n",
    "    display(results)\n",
    "    results.to_csv(f'{model_type}_batch_size_{batch_size}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aws_neuron_tensorflow_p36",
   "language": "python",
   "name": "aws_neuron_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
