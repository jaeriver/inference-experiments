{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AWS Inferentia inference on Amazon EC2 Inf1 instance\n",
    "This example demonstrates AWS Inferentia inference with TensorFlow and AWS Neuron SDK compiler and runtime\n",
    "\n",
    "This example was tested on Amazon EC2 `inf1.xlarge` the following AWS Deep Learning AMI: \n",
    "`Deep Learning AMI (Ubuntu 18.04) Version 35.0`\n",
    "\n",
    "Run this notebook using the following conda environment:\n",
    "`aws_neuron_tensorflow_p36`\n",
    "\n",
    "Prepare your imagenet validation TFRecord files using the following helper script:\n",
    "https://github.com/tensorflow/models/blob/archive/research/inception/inception/data/download_and_preprocess_imagenet.sh\n",
    "\n",
    "Save it to `/home/ubuntu/datasets/` or update the dataset location in the `get_dataset()` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install matplotlib pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n"
     ]
    }
   ],
   "source": [
    "!/opt/aws/neuron/bin/neuron-cli reset\n",
    "import os\n",
    "import time\n",
    "import shutil\n",
    "import json\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow.neuron as tfn\n",
    "import tensorflow.compat.v1.keras as keras\n",
    "from tensorflow.keras.applications import ( \n",
    "    xception,\n",
    "    vgg16,\n",
    "    vgg19,\n",
    "    resnet,\n",
    "    resnet50,\n",
    "    resnet_v2,\n",
    "    inception_v3,\n",
    "    inception_resnet_v2,\n",
    "    mobilenet,\n",
    "    densenet,\n",
    "    nasnet,\n",
    "    mobilenet_v2\n",
    ")\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from concurrent import futures\n",
    "from itertools import compress\n",
    "\n",
    "models = {\n",
    "    'xception':xception,\n",
    "    'vgg16':vgg16,\n",
    "    'vgg19':vgg19,\n",
    "    'resnet50':resnet50,\n",
    "    'resnet101':resnet,\n",
    "    'resnet152':resnet,\n",
    "    'resnet50_v2':resnet_v2,\n",
    "    'resnet101_v2':resnet_v2,\n",
    "    'resnet152_v2':resnet_v2,\n",
    "#     'resnext50':resnext,\n",
    "#     'resnext101':resnext,\n",
    "    'inception_v3':inception_v3,\n",
    "    'inception_resnet_v2':inception_resnet_v2,\n",
    "    'mobilenet':mobilenet,\n",
    "    'densenet121':densenet,\n",
    "    'densenet169':densenet,\n",
    "    'densenet201':densenet,\n",
    "    'nasnetlarge':nasnet,\n",
    "    'nasnetmobile':nasnet,\n",
    "    'mobilenet_v2':mobilenet_v2\n",
    "}\n",
    "\n",
    "models_detail = {\n",
    "#     'xception':xception.Xception(weights='imagenet',include_top=False),\n",
    "#     'vgg16':vgg16.VGG16(weights='imagenet'),\n",
    "#     'vgg19':vgg19.VGG19(weights='imagenet'),\n",
    "#     'resnet50':resnet.ResNet50(weights='imagenet'),\n",
    "#     'resnet101':resnet.ResNet101(weights='imagenet'),\n",
    "#     'resnet152':resnet.ResNet152(weights='imagenet'),\n",
    "#     'resnet50_v2':resnet_v2.ResNet50V2(weights='imagenet'),\n",
    "#     'resnet101_v2':resnet_v2.ResNet101V2(weights='imagenet'),\n",
    "#     'resnet152_v2':resnet_v2.ResNet152V2(weights='imagenet'),\n",
    "#     'resnext50':resnext.ResNeXt50(weights='imagenet'),\n",
    "#     'resnext101':resnext.ResNeXt101(weights='imagenet'),\n",
    "#     'inception_v3':inception_v3.InceptionV3(weights='imagenet',include_top=False),\n",
    "#     'inception_resnet_v2':inception_resnet_v2.InceptionResNetV2(weights='imagenet'),\n",
    "#     'mobilenet':mobilenet.MobileNet(weights='imagenet'),\n",
    "#     'densenet121':densenet.DenseNet121(weights='imagenet'),\n",
    "#     'densenet169':densenet.DenseNet169(weights='imagenet'),\n",
    "#     'densenet201':densenet.DenseNet201(weights='imagenet'),\n",
    "#     'nasnetlarge':nasnet.NASNetLarge(weights='imagenet'),\n",
    "#     'nasnetmobile':nasnet.NASNetMobile(weights='imagenet'),\n",
    "#     'mobilenet_v2':mobilenet_v2.MobileNetV2(weights='imagenet')\n",
    "}\n",
    "\n",
    "print('test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resnet50 FP32 saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Export SavedModel\n",
    "# model_type = 'resnet50'\n",
    "\n",
    "# saved_model_dir = f'{model_type}_saved_model'\n",
    "# shutil.rmtree(saved_model_dir, ignore_errors=True)\n",
    "\n",
    "keras.backend.set_learning_phase(0)\n",
    "# model = ResNet50(weights='imagenet')\n",
    "# tf.saved_model.simple_save(session = keras.backend.get_session(),\n",
    "#                            export_dir = saved_model_dir,\n",
    "#                            inputs = {'input_1:0': model.inputs[0]},\n",
    "#                            outputs = {'probs/Softmax:0': model.outputs[0]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile models with different batch sizes and cores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_inf1_model(saved_model_dir, inf1_model_dir, batch_size=1, num_cores=1, use_static_weights=False):\n",
    "    print(f'-----------batch size: {batch_size}, num cores: {num_cores}----------')\n",
    "    print('Compiling...')\n",
    "    \n",
    "    compiled_model_dir = f'{model_type}_batch_{batch_size}_inf1_cores_{num_cores}'\n",
    "    inf1_compiled_model_dir = os.path.join(inf1_model_dir, compiled_model_dir)\n",
    "    shutil.rmtree(inf1_compiled_model_dir, ignore_errors=True)\n",
    "\n",
    "    example_input = np.zeros([batch_size,224,224,3], dtype='float32')\n",
    "\n",
    "    compiler_args = ['--verbose','1', '--neuroncore-pipeline-cores', str(num_cores)]\n",
    "    if use_static_weights:\n",
    "        compiler_args.append('--static-weights')\n",
    "    \n",
    "    start_time = time.time()\n",
    "    compiled_res = tfn.saved_model.compile(model_dir = saved_model_dir,\n",
    "                            model_feed_dict={'input_1:0': example_input},\n",
    "                            new_model_dir = inf1_compiled_model_dir,\n",
    "                            dynamic_batch_size=True,\n",
    "                            compiler_args = compiler_args)\n",
    "    print(f'Compile time: {time.time() - start_time}')\n",
    "    \n",
    "    compile_success = False\n",
    "    perc_on_inf = compiled_res['OnNeuronRatio'] * 100\n",
    "    if perc_on_inf > 50:\n",
    "        compile_success = True\n",
    "            \n",
    "    print(inf1_compiled_model_dir)\n",
    "    print(compiled_res)\n",
    "    print('----------- Done! ----------- \\n')\n",
    "    \n",
    "    return compile_success"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use `tf.data` to read ImageNet validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deserialize_image_record(record):\n",
    "    feature_map = {'image/encoded': tf.io.FixedLenFeature([], tf.string, ''),\n",
    "                  'image/class/label': tf.io.FixedLenFeature([1], tf.int64, -1),\n",
    "                  'image/class/text': tf.io.FixedLenFeature([], tf.string, '')}\n",
    "    obj = tf.io.parse_single_example(serialized=record, features=feature_map)\n",
    "    imgdata = obj['image/encoded']\n",
    "    label = tf.cast(obj['image/class/label'], tf.int32)   \n",
    "    label_text = tf.cast(obj['image/class/text'], tf.string)   \n",
    "    return imgdata, label, label_text\n",
    "\n",
    "def val_preprocessing(record):\n",
    "    imgdata, label, label_text = deserialize_image_record(record)\n",
    "    label -= 1\n",
    "    image = tf.io.decode_jpeg(imgdata, channels=3, \n",
    "                              fancy_upscaling=False, \n",
    "                              dct_method='INTEGER_FAST')\n",
    "\n",
    "    shape = tf.shape(image)\n",
    "    height = tf.cast(shape[0], tf.float32)\n",
    "    width = tf.cast(shape[1], tf.float32)\n",
    "    side = tf.cast(tf.convert_to_tensor(256, dtype=tf.int32), tf.float32)\n",
    "\n",
    "    scale = tf.cond(tf.greater(height, width),\n",
    "                  lambda: side / width,\n",
    "                  lambda: side / height)\n",
    "    \n",
    "    new_height = tf.cast(tf.math.rint(height * scale), tf.int32)\n",
    "    new_width = tf.cast(tf.math.rint(width * scale), tf.int32)\n",
    "    \n",
    "    image = tf.image.resize(image, [new_height, new_width], method='bicubic')\n",
    "    image = tf.image.resize_with_crop_or_pad(image, 224, 224)\n",
    "    \n",
    "    image = models[model_type].preprocess_input(image)\n",
    "    \n",
    "    return image, label, label_text\n",
    "\n",
    "def get_dataset(batch_size, use_cache=False):\n",
    "    data_dir = '/home/ubuntu/datasets/images-1000/*'\n",
    "    files = tf.io.gfile.glob(os.path.join(data_dir))\n",
    "    dataset = tf.data.TFRecordDataset(files)\n",
    "    \n",
    "    dataset = dataset.map(map_func=val_preprocessing, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    dataset = dataset.batch(batch_size=batch_size)\n",
    "    dataset = dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "    dataset = dataset.repeat(count=1)\n",
    "    \n",
    "    if use_cache:\n",
    "        shutil.rmtree('tfdatacache', ignore_errors=True)\n",
    "        os.mkdir('tfdatacache')\n",
    "        dataset = dataset.cache(f'./tfdatacache/imagenet_val')\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single AWS Inferentia chip execution\n",
    "* Single core compiled models with automatic data parallel model upto 4 cores\n",
    "* Multi-core compiled models for pipeline execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def inf1_predict_benchmark_single_threaded(neuron_saved_model_name, batch_size, user_batch_size, num_cores, use_cache=False, warm_up=10):\n",
    "    print(f'Running model {neuron_saved_model_name}, user_batch_size: {user_batch_size}\\n')\n",
    "\n",
    "    model_inf1 = tf.contrib.predictor.from_saved_model(neuron_saved_model_name)\n",
    "\n",
    "    first_iter_time = 0\n",
    "    iter_times = []\n",
    "    pred_labels = []\n",
    "    actual_labels = []\n",
    "    display_threshold = 0\n",
    "    warm_up = 10\n",
    "\n",
    "    ds = get_dataset(user_batch_size, use_cache)\n",
    "\n",
    "    ds_iter = ds.make_initializable_iterator()\n",
    "    ds_next = ds_iter.get_next()\n",
    "    ds_init_op = ds_iter.initializer\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        if use_cache:\n",
    "            sess.run(ds_init_op)\n",
    "            print('\\nCaching dataset ...')\n",
    "            start_time = time.time()\n",
    "            try:\n",
    "                while True:\n",
    "                    (validation_ds,label,_) = sess.run(ds_next)\n",
    "            except tf.errors.OutOfRangeError:\n",
    "                pass\n",
    "            print(f'Caching finished: {time.time()-start_time} sec')  \n",
    "\n",
    "        try:\n",
    "            sess.run(ds_init_op)\n",
    "            counter = 0\n",
    "            \n",
    "            total_datas = 1000\n",
    "            display_every = 100\n",
    "            display_threshold = display_every\n",
    "            \n",
    "            ipname = list(model_inf1.feed_tensors.keys())[0]\n",
    "            resname = list(model_inf1.fetch_tensors.keys())[0]\n",
    "            \n",
    "            walltime_start = time.time()\n",
    "            warmup_time = []\n",
    "            extend_time = []\n",
    "            while True:\n",
    "                sess_start = time.time()\n",
    "                (validation_ds,batch_labels,_) = sess.run(ds_next)\n",
    "                \n",
    "                model_feed_dict={ipname: validation_ds}\n",
    "#                 warmup_start = time.time()\n",
    "#                 if counter == 0:\n",
    "#                     for i in range(warm_up):\n",
    "#                         _ = model_inf1(model_feed_dict);                    \n",
    "#                 warmup_time.append(time.time() - warmup_start)\n",
    "                start_time =time.time()\n",
    "                inf1_results = model_inf1(model_feed_dict);\n",
    "                if counter == 0:\n",
    "                    first_iter_time = time.time() - start_time\n",
    "                else:\n",
    "                    iter_times.append(time.time() - start_time)\n",
    "                \n",
    "                actual_labels.extend(label for label_list in batch_labels for label in label_list)\n",
    "                pred_labels.extend(list(np.argmax(inf1_results[resname], axis=1)))\n",
    "                \n",
    "                print(np.argmax(inf1_results[resname],axis=2))\n",
    "                if counter*user_batch_size >= display_threshold:\n",
    "                    print(f'Images {counter*user_batch_size}/{total_datas}. Average i/s {np.mean(user_batch_size/np.array(iter_times[-display_every:]))}')\n",
    "                    display_threshold+=display_every\n",
    "\n",
    "                counter+=1\n",
    "                break\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            pass\n",
    "    print(actual_labels)\n",
    "    print(pred_labels)\n",
    "    acc_inf1 = np.sum(np.array(actual_labels) == np.array(pred_labels))/len(actual_labels)\n",
    "    iter_times = np.array(iter_times)\n",
    "    \n",
    "    results = pd.DataFrame(columns = [f'inf1_compiled_batch_size_{batch_size}_compiled_cores_{num_cores}'])\n",
    "    results.loc['compiled_batch_size']     = [batch_size]\n",
    "    results.loc['user_batch_size']         = [user_batch_size]\n",
    "    results.loc['accuracy']                = [acc_inf1]\n",
    "    results.loc['first_prediction_time']   = [first_iter_time]\n",
    "    results.loc['average_prediction_time'] = [np.mean(iter_times)]\n",
    "    results.loc['wall_time']               = [time.time() - walltime_start]\n",
    "    display(results.T)\n",
    "#     shutil.rmtree(neuron_saved_model_name, ignore_errors=True)\n",
    "\n",
    "\n",
    "    return results, iter_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inf1_compiled_model_dir: xception_inf1_saved_models/xception_batch_1_inf1_cores_1\n",
      "Running model xception_inf1_saved_models/xception_batch_1_inf1_cores_1, user_batch_size: 64\n",
      "\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n",
      "INFO:tensorflow:The specified SavedModel has no variables; no checkpoints were restored.\n",
      "[[[0 0 0 ... 4 0 6]\n",
      "  [6 6 5 ... 4 6 0]\n",
      "  [6 6 5 ... 2 6 0]\n",
      "  ...\n",
      "  [6 6 5 ... 2 6 6]\n",
      "  [6 6 5 ... 2 6 6]\n",
      "  [6 6 0 ... 5 0 0]]\n",
      "\n",
      " [[0 0 0 ... 0 0 0]\n",
      "  [5 0 5 ... 0 0 0]\n",
      "  [5 0 5 ... 0 0 0]\n",
      "  ...\n",
      "  [5 6 5 ... 0 0 6]\n",
      "  [5 6 5 ... 0 0 6]\n",
      "  [5 6 5 ... 0 0 0]]\n",
      "\n",
      " [[5 5 0 ... 3 0 0]\n",
      "  [5 5 0 ... 2 0 0]\n",
      "  [4 5 0 ... 1 0 0]\n",
      "  ...\n",
      "  [4 5 0 ... 1 0 0]\n",
      "  [4 1 0 ... 5 1 0]\n",
      "  [4 4 0 ... 5 0 0]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0 5 5 ... 6 0 0]\n",
      "  [0 5 5 ... 6 0 0]\n",
      "  [0 5 5 ... 6 0 0]\n",
      "  ...\n",
      "  [0 5 5 ... 6 0 0]\n",
      "  [0 5 5 ... 6 0 0]\n",
      "  [0 5 5 ... 6 0 0]]\n",
      "\n",
      " [[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 5 0 ... 2 0 0]\n",
      "  ...\n",
      "  [0 4 4 ... 3 0 0]\n",
      "  [0 4 1 ... 4 0 0]\n",
      "  [0 4 0 ... 4 0 0]]\n",
      "\n",
      " [[6 0 0 ... 6 3 4]\n",
      "  [6 0 0 ... 0 3 4]\n",
      "  [6 0 0 ... 6 3 4]\n",
      "  ...\n",
      "  [6 6 0 ... 6 5 4]\n",
      "  [0 6 0 ... 5 5 5]\n",
      "  [0 6 0 ... 6 3 6]]]\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63]\n",
      "[array([[0, 0, 4, ..., 3, 0, 0],\n",
      "       [0, 0, 4, ..., 4, 0, 0],\n",
      "       [0, 0, 4, ..., 4, 0, 0],\n",
      "       ...,\n",
      "       [0, 0, 4, ..., 2, 0, 0],\n",
      "       [4, 2, 4, ..., 2, 4, 0],\n",
      "       [3, 4, 3, ..., 3, 3, 4]]), array([[0, 0, 0, ..., 3, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 4, ..., 0, 0, 0],\n",
      "       ...,\n",
      "       [4, 0, 4, ..., 0, 0, 0],\n",
      "       [4, 4, 4, ..., 0, 0, 0],\n",
      "       [4, 4, 4, ..., 0, 0, 5]]), array([[4, 5, 0, ..., 3, 0, 6],\n",
      "       [4, 5, 0, ..., 3, 3, 6],\n",
      "       [4, 1, 0, ..., 3, 0, 6],\n",
      "       ...,\n",
      "       [4, 2, 0, ..., 4, 0, 6],\n",
      "       [2, 2, 0, ..., 4, 0, 6],\n",
      "       [4, 3, 0, ..., 4, 0, 6]]), array([[3, 2, 3, ..., 3, 0, 0],\n",
      "       [3, 2, 3, ..., 3, 0, 0],\n",
      "       [4, 2, 2, ..., 4, 0, 0],\n",
      "       ...,\n",
      "       [3, 4, 2, ..., 4, 6, 0],\n",
      "       [3, 4, 2, ..., 5, 6, 6],\n",
      "       [3, 4, 2, ..., 5, 6, 6]]), array([[0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 4, 0, ..., 0, 0, 0],\n",
      "       ...,\n",
      "       [0, 5, 0, ..., 0, 0, 0],\n",
      "       [0, 5, 0, ..., 6, 0, 0],\n",
      "       [6, 6, 0, ..., 6, 6, 0]]), array([[4, 4, 0, ..., 2, 4, 5],\n",
      "       [4, 0, 0, ..., 2, 5, 5],\n",
      "       [4, 0, 0, ..., 1, 5, 5],\n",
      "       ...,\n",
      "       [4, 5, 0, ..., 1, 5, 1],\n",
      "       [4, 5, 0, ..., 1, 5, 1],\n",
      "       [4, 5, 0, ..., 5, 2, 4]]), array([[3, 0, 0, ..., 3, 0, 0],\n",
      "       [3, 0, 0, ..., 0, 2, 0],\n",
      "       [4, 0, 0, ..., 0, 2, 0],\n",
      "       ...,\n",
      "       [3, 0, 0, ..., 0, 4, 0],\n",
      "       [3, 0, 0, ..., 6, 4, 0],\n",
      "       [3, 0, 0, ..., 5, 4, 6]]), array([[0, 0, 0, ..., 0, 0, 0],\n",
      "       [2, 0, 4, ..., 0, 0, 2],\n",
      "       [2, 0, 3, ..., 1, 2, 2],\n",
      "       ...,\n",
      "       [3, 5, 4, ..., 0, 2, 3],\n",
      "       [3, 5, 4, ..., 0, 2, 3],\n",
      "       [3, 4, 4, ..., 0, 4, 3]]), array([[0, 0, 0, ..., 0, 1, 3],\n",
      "       [1, 1, 0, ..., 0, 1, 3],\n",
      "       [1, 0, 0, ..., 0, 1, 1],\n",
      "       ...,\n",
      "       [1, 4, 1, ..., 0, 1, 1],\n",
      "       [1, 4, 1, ..., 5, 1, 1],\n",
      "       [1, 6, 1, ..., 5, 1, 0]]), array([[0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 4, 0, ..., 6, 0, 0],\n",
      "       [0, 4, 0, ..., 6, 0, 0],\n",
      "       ...,\n",
      "       [0, 3, 0, ..., 6, 0, 0],\n",
      "       [6, 4, 0, ..., 4, 0, 6],\n",
      "       [5, 3, 2, ..., 4, 3, 4]]), array([[0, 0, 3, ..., 0, 0, 0],\n",
      "       [0, 3, 3, ..., 0, 0, 4],\n",
      "       [0, 3, 2, ..., 0, 0, 4],\n",
      "       ...,\n",
      "       [3, 3, 2, ..., 5, 0, 4],\n",
      "       [3, 3, 2, ..., 5, 0, 4],\n",
      "       [3, 2, 2, ..., 5, 0, 4]]), array([[2, 0, 3, ..., 3, 0, 3],\n",
      "       [2, 0, 3, ..., 3, 0, 3],\n",
      "       [0, 4, 4, ..., 2, 0, 4],\n",
      "       ...,\n",
      "       [0, 2, 4, ..., 6, 0, 4],\n",
      "       [0, 2, 4, ..., 5, 0, 4],\n",
      "       [0, 2, 4, ..., 5, 0, 4]]), array([[0, 0, 3, ..., 0, 0, 0],\n",
      "       [0, 0, 2, ..., 0, 0, 0],\n",
      "       [0, 0, 3, ..., 0, 0, 2],\n",
      "       ...,\n",
      "       [0, 0, 3, ..., 6, 0, 2],\n",
      "       [0, 5, 3, ..., 6, 0, 2],\n",
      "       [0, 6, 3, ..., 6, 6, 2]]), array([[4, 4, 4, ..., 0, 0, 0],\n",
      "       [4, 4, 4, ..., 0, 0, 0],\n",
      "       [3, 4, 4, ..., 0, 0, 0],\n",
      "       ...,\n",
      "       [2, 4, 4, ..., 0, 0, 0],\n",
      "       [2, 4, 3, ..., 5, 0, 6],\n",
      "       [0, 4, 1, ..., 5, 6, 6]]), array([[0, 0, 0, ..., 6, 0, 0],\n",
      "       [0, 0, 5, ..., 5, 0, 0],\n",
      "       [0, 0, 5, ..., 5, 0, 0],\n",
      "       ...,\n",
      "       [5, 5, 5, ..., 5, 0, 2],\n",
      "       [5, 5, 5, ..., 5, 0, 5],\n",
      "       [6, 6, 6, ..., 5, 0, 6]]), array([[2, 0, 4, ..., 0, 0, 0],\n",
      "       [2, 0, 4, ..., 0, 0, 0],\n",
      "       [2, 0, 3, ..., 1, 0, 0],\n",
      "       ...,\n",
      "       [2, 3, 2, ..., 1, 0, 0],\n",
      "       [2, 3, 2, ..., 5, 0, 0],\n",
      "       [0, 3, 2, ..., 6, 0, 0]]), array([[0, 4, 0, ..., 6, 0, 0],\n",
      "       [0, 4, 0, ..., 5, 4, 0],\n",
      "       [0, 4, 5, ..., 5, 4, 0],\n",
      "       ...,\n",
      "       [0, 4, 4, ..., 5, 3, 0],\n",
      "       [0, 4, 4, ..., 5, 2, 0],\n",
      "       [6, 4, 3, ..., 6, 2, 0]]), array([[0, 0, 3, ..., 4, 2, 3],\n",
      "       [0, 0, 4, ..., 4, 0, 0],\n",
      "       [0, 0, 4, ..., 5, 0, 0],\n",
      "       ...,\n",
      "       [0, 5, 4, ..., 5, 0, 0],\n",
      "       [0, 5, 5, ..., 5, 0, 0],\n",
      "       [0, 3, 6, ..., 6, 0, 0]]), array([[0, 0, 0, ..., 0, 0, 3],\n",
      "       [0, 0, 0, ..., 0, 0, 3],\n",
      "       [0, 0, 0, ..., 0, 0, 2],\n",
      "       ...,\n",
      "       [0, 0, 0, ..., 0, 0, 2],\n",
      "       [0, 0, 0, ..., 6, 0, 2],\n",
      "       [6, 6, 6, ..., 6, 0, 2]]), array([[0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 4, ..., 0, 2, 0],\n",
      "       [0, 0, 3, ..., 0, 2, 0],\n",
      "       ...,\n",
      "       [0, 4, 2, ..., 0, 3, 0],\n",
      "       [0, 4, 2, ..., 6, 3, 0],\n",
      "       [0, 4, 2, ..., 6, 3, 0]]), array([[0, 0, 0, ..., 0, 3, 0],\n",
      "       [2, 0, 0, ..., 0, 3, 0],\n",
      "       [2, 0, 0, ..., 0, 3, 0],\n",
      "       ...,\n",
      "       [2, 0, 0, ..., 5, 3, 0],\n",
      "       [2, 5, 5, ..., 5, 2, 0],\n",
      "       [5, 6, 6, ..., 5, 2, 6]]), array([[4, 0, 0, ..., 5, 0, 5],\n",
      "       [5, 0, 0, ..., 5, 0, 6],\n",
      "       [5, 0, 0, ..., 5, 0, 6],\n",
      "       ...,\n",
      "       [5, 0, 6, ..., 5, 0, 6],\n",
      "       [5, 0, 6, ..., 5, 0, 6],\n",
      "       [5, 6, 6, ..., 4, 0, 6]]), array([[0, 0, 0, ..., 4, 4, 4],\n",
      "       [3, 0, 0, ..., 4, 4, 0],\n",
      "       [4, 4, 0, ..., 4, 4, 5],\n",
      "       ...,\n",
      "       [5, 4, 0, ..., 4, 4, 5],\n",
      "       [5, 4, 0, ..., 4, 4, 5],\n",
      "       [4, 4, 0, ..., 4, 4, 5]]), array([[4, 6, 0, ..., 5, 6, 4],\n",
      "       [4, 0, 0, ..., 5, 5, 0],\n",
      "       [4, 0, 0, ..., 5, 6, 0],\n",
      "       ...,\n",
      "       [4, 4, 4, ..., 1, 6, 0],\n",
      "       [5, 5, 4, ..., 1, 6, 0],\n",
      "       [6, 6, 5, ..., 6, 6, 0]]), array([[4, 0, 0, ..., 0, 3, 0],\n",
      "       [4, 0, 2, ..., 0, 3, 0],\n",
      "       [4, 0, 1, ..., 6, 3, 0],\n",
      "       ...,\n",
      "       [3, 2, 2, ..., 4, 3, 0],\n",
      "       [3, 2, 2, ..., 4, 3, 0],\n",
      "       [3, 2, 2, ..., 4, 3, 0]]), array([[2, 0, 3, ..., 3, 0, 2],\n",
      "       [2, 0, 3, ..., 3, 0, 3],\n",
      "       [2, 0, 3, ..., 2, 0, 3],\n",
      "       ...,\n",
      "       [2, 0, 3, ..., 4, 4, 3],\n",
      "       [3, 0, 3, ..., 4, 4, 3],\n",
      "       [3, 0, 3, ..., 4, 4, 3]]), array([[2, 0, 2, ..., 0, 0, 0],\n",
      "       [3, 0, 1, ..., 0, 0, 0],\n",
      "       [0, 0, 1, ..., 0, 0, 0],\n",
      "       ...,\n",
      "       [4, 2, 2, ..., 4, 0, 0],\n",
      "       [5, 2, 2, ..., 5, 6, 6],\n",
      "       [5, 6, 0, ..., 5, 6, 6]]), array([[2, 0, 4, ..., 0, 0, 0],\n",
      "       [4, 0, 0, ..., 0, 0, 2],\n",
      "       [1, 0, 0, ..., 0, 0, 2],\n",
      "       ...,\n",
      "       [4, 4, 4, ..., 5, 0, 2],\n",
      "       [3, 1, 4, ..., 5, 0, 2],\n",
      "       [3, 4, 3, ..., 5, 6, 2]]), array([[0, 3, 4, ..., 0, 0, 3],\n",
      "       [0, 2, 4, ..., 0, 0, 3],\n",
      "       [0, 0, 5, ..., 0, 0, 3],\n",
      "       ...,\n",
      "       [0, 2, 5, ..., 0, 0, 4],\n",
      "       [0, 2, 5, ..., 0, 0, 3],\n",
      "       [0, 0, 3, ..., 0, 0, 3]]), array([[3, 0, 2, ..., 0, 4, 0],\n",
      "       [3, 0, 2, ..., 0, 4, 0],\n",
      "       [2, 0, 1, ..., 0, 0, 0],\n",
      "       ...,\n",
      "       [0, 4, 2, ..., 2, 2, 0],\n",
      "       [4, 4, 2, ..., 3, 4, 4],\n",
      "       [4, 4, 3, ..., 4, 4, 4]]), array([[0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 3, 0],\n",
      "       [0, 0, 0, ..., 0, 3, 0],\n",
      "       ...,\n",
      "       [0, 0, 0, ..., 0, 3, 0],\n",
      "       [5, 0, 0, ..., 0, 3, 0],\n",
      "       [5, 0, 0, ..., 0, 3, 0]]), array([[5, 0, 5, ..., 3, 5, 0],\n",
      "       [5, 0, 5, ..., 3, 5, 0],\n",
      "       [5, 0, 5, ..., 4, 5, 0],\n",
      "       ...,\n",
      "       [5, 0, 5, ..., 4, 3, 0],\n",
      "       [5, 0, 5, ..., 4, 1, 6],\n",
      "       [6, 0, 6, ..., 6, 6, 6]]), array([[0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       ...,\n",
      "       [1, 3, 2, ..., 0, 3, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       [1, 3, 3, ..., 1, 2, 0]]), array([[0, 1, 0, ..., 2, 0, 0],\n",
      "       [0, 1, 0, ..., 2, 0, 0],\n",
      "       [0, 1, 0, ..., 2, 1, 0],\n",
      "       ...,\n",
      "       [0, 2, 0, ..., 2, 2, 0],\n",
      "       [1, 2, 0, ..., 2, 1, 4],\n",
      "       [1, 1, 0, ..., 2, 1, 4]]), array([[0, 2, 0, ..., 2, 2, 0],\n",
      "       [0, 1, 0, ..., 2, 2, 0],\n",
      "       [0, 1, 0, ..., 1, 2, 6],\n",
      "       ...,\n",
      "       [0, 2, 0, ..., 2, 2, 0],\n",
      "       [5, 2, 0, ..., 2, 2, 5],\n",
      "       [5, 2, 2, ..., 2, 2, 6]]), array([[0, 2, 3, ..., 3, 2, 0],\n",
      "       [0, 2, 3, ..., 3, 3, 0],\n",
      "       [0, 0, 3, ..., 3, 2, 0],\n",
      "       ...,\n",
      "       [0, 5, 3, ..., 4, 2, 0],\n",
      "       [0, 5, 3, ..., 5, 2, 0],\n",
      "       [0, 5, 3, ..., 5, 2, 0]]), array([[0, 2, 4, ..., 4, 3, 0],\n",
      "       [0, 2, 4, ..., 4, 4, 0],\n",
      "       [0, 0, 4, ..., 4, 4, 0],\n",
      "       ...,\n",
      "       [0, 4, 3, ..., 4, 4, 2],\n",
      "       [0, 4, 3, ..., 4, 4, 2],\n",
      "       [0, 4, 4, ..., 4, 4, 2]]), array([[0, 4, 0, ..., 0, 3, 0],\n",
      "       [0, 4, 0, ..., 0, 3, 0],\n",
      "       [0, 4, 0, ..., 0, 3, 2],\n",
      "       ...,\n",
      "       [0, 3, 0, ..., 0, 3, 3],\n",
      "       [0, 3, 0, ..., 1, 2, 4],\n",
      "       [0, 2, 0, ..., 1, 0, 3]]), array([[0, 3, 0, ..., 0, 0, 0],\n",
      "       [0, 3, 0, ..., 0, 0, 0],\n",
      "       [0, 3, 0, ..., 0, 0, 0],\n",
      "       ...,\n",
      "       [0, 3, 3, ..., 4, 0, 0],\n",
      "       [0, 4, 3, ..., 3, 0, 6],\n",
      "       [5, 3, 3, ..., 3, 3, 6]]), array([[0, 0, 0, ..., 0, 3, 4],\n",
      "       [0, 0, 0, ..., 0, 3, 5],\n",
      "       [0, 0, 0, ..., 6, 3, 5],\n",
      "       ...,\n",
      "       [6, 2, 6, ..., 6, 3, 5],\n",
      "       [6, 2, 4, ..., 4, 3, 3],\n",
      "       [4, 3, 4, ..., 4, 3, 3]]), array([[3, 0, 4, ..., 0, 0, 0],\n",
      "       [3, 0, 4, ..., 0, 0, 0],\n",
      "       [3, 0, 4, ..., 6, 0, 0],\n",
      "       ...,\n",
      "       [3, 5, 3, ..., 5, 4, 5],\n",
      "       [5, 5, 5, ..., 5, 6, 5],\n",
      "       [6, 5, 5, ..., 5, 6, 6]]), array([[0, 0, 0, ..., 3, 3, 0],\n",
      "       [0, 0, 0, ..., 3, 3, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       ...,\n",
      "       [0, 0, 0, ..., 0, 0, 3],\n",
      "       [3, 6, 0, ..., 4, 0, 3],\n",
      "       [3, 6, 0, ..., 4, 0, 3]]), array([[0, 0, 0, ..., 0, 0, 3],\n",
      "       [0, 0, 4, ..., 0, 0, 4],\n",
      "       [2, 0, 3, ..., 0, 4, 4],\n",
      "       ...,\n",
      "       [2, 6, 3, ..., 0, 3, 4],\n",
      "       [3, 6, 3, ..., 6, 3, 4],\n",
      "       [3, 4, 3, ..., 6, 3, 3]]), array([[0, 0, 3, ..., 0, 0, 0],\n",
      "       [0, 0, 4, ..., 0, 1, 0],\n",
      "       [0, 0, 4, ..., 0, 1, 0],\n",
      "       ...,\n",
      "       [0, 0, 3, ..., 0, 1, 0],\n",
      "       [1, 0, 3, ..., 0, 1, 0],\n",
      "       [0, 6, 3, ..., 0, 1, 6]]), array([[3, 3, 0, ..., 3, 3, 0],\n",
      "       [4, 3, 3, ..., 4, 4, 4],\n",
      "       [4, 4, 4, ..., 4, 4, 4],\n",
      "       ...,\n",
      "       [4, 4, 4, ..., 4, 3, 0],\n",
      "       [0, 4, 4, ..., 4, 3, 5],\n",
      "       [0, 4, 2, ..., 4, 3, 6]]), array([[0, 0, 1, ..., 0, 0, 0],\n",
      "       [0, 0, 1, ..., 0, 0, 0],\n",
      "       [0, 0, 1, ..., 0, 0, 0],\n",
      "       ...,\n",
      "       [0, 0, 2, ..., 0, 0, 0],\n",
      "       [6, 0, 2, ..., 6, 0, 0],\n",
      "       [6, 0, 3, ..., 6, 0, 0]]), array([[0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 5, ..., 0, 4, 0],\n",
      "       ...,\n",
      "       [5, 6, 4, ..., 5, 4, 5],\n",
      "       [5, 5, 4, ..., 5, 4, 5],\n",
      "       [5, 5, 4, ..., 4, 4, 5]]), array([[0, 0, 4, ..., 0, 0, 0],\n",
      "       [0, 0, 4, ..., 2, 2, 0],\n",
      "       [4, 0, 4, ..., 4, 2, 0],\n",
      "       ...,\n",
      "       [4, 4, 4, ..., 3, 2, 4],\n",
      "       [4, 4, 4, ..., 4, 4, 4],\n",
      "       [4, 4, 4, ..., 3, 2, 4]]), array([[0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       ...,\n",
      "       [5, 0, 0, ..., 0, 2, 0],\n",
      "       [3, 0, 0, ..., 6, 2, 0],\n",
      "       [1, 0, 0, ..., 6, 2, 6]]), array([[0, 0, 0, ..., 2, 1, 0],\n",
      "       [0, 0, 0, ..., 2, 1, 0],\n",
      "       [0, 0, 0, ..., 2, 1, 0],\n",
      "       ...,\n",
      "       [0, 0, 0, ..., 2, 1, 0],\n",
      "       [0, 0, 0, ..., 5, 1, 0],\n",
      "       [0, 0, 0, ..., 5, 1, 0]]), array([[4, 0, 0, ..., 4, 4, 0],\n",
      "       [0, 0, 0, ..., 4, 4, 0],\n",
      "       [0, 0, 0, ..., 5, 4, 0],\n",
      "       ...,\n",
      "       [0, 0, 0, ..., 5, 0, 0],\n",
      "       [0, 0, 0, ..., 5, 0, 0],\n",
      "       [0, 0, 2, ..., 5, 0, 5]]), array([[0, 0, 3, ..., 2, 3, 3],\n",
      "       [5, 0, 3, ..., 2, 0, 0],\n",
      "       [5, 0, 3, ..., 2, 0, 6],\n",
      "       ...,\n",
      "       [2, 0, 3, ..., 2, 0, 4],\n",
      "       [2, 4, 3, ..., 3, 1, 4],\n",
      "       [2, 4, 3, ..., 2, 1, 4]]), array([[4, 4, 4, ..., 4, 4, 0],\n",
      "       [4, 4, 4, ..., 4, 4, 0],\n",
      "       [4, 4, 2, ..., 4, 4, 0],\n",
      "       ...,\n",
      "       [4, 2, 2, ..., 2, 4, 1],\n",
      "       [4, 2, 4, ..., 4, 4, 1],\n",
      "       [4, 2, 4, ..., 4, 2, 0]]), array([[0, 0, 0, ..., 0, 3, 0],\n",
      "       [0, 0, 0, ..., 0, 4, 0],\n",
      "       [0, 4, 0, ..., 0, 4, 0],\n",
      "       ...,\n",
      "       [1, 3, 0, ..., 0, 1, 0],\n",
      "       [1, 3, 1, ..., 1, 1, 0],\n",
      "       [3, 3, 1, ..., 2, 1, 0]]), array([[2, 1, 0, ..., 3, 3, 0],\n",
      "       [2, 1, 0, ..., 3, 3, 0],\n",
      "       [2, 1, 0, ..., 3, 3, 0],\n",
      "       ...,\n",
      "       [2, 0, 0, ..., 3, 4, 0],\n",
      "       [5, 0, 5, ..., 4, 4, 5],\n",
      "       [5, 0, 5, ..., 4, 4, 5]]), array([[1, 2, 0, ..., 0, 0, 0],\n",
      "       [0, 3, 0, ..., 0, 0, 0],\n",
      "       [0, 3, 0, ..., 0, 0, 0],\n",
      "       ...,\n",
      "       [0, 4, 0, ..., 5, 2, 0],\n",
      "       [0, 3, 0, ..., 5, 2, 0],\n",
      "       [0, 4, 0, ..., 4, 2, 0]]), array([[0, 4, 0, ..., 0, 4, 0],\n",
      "       [0, 4, 5, ..., 4, 4, 0],\n",
      "       [0, 4, 4, ..., 4, 4, 0],\n",
      "       ...,\n",
      "       [0, 4, 5, ..., 4, 4, 0],\n",
      "       [0, 4, 6, ..., 4, 4, 0],\n",
      "       [5, 5, 5, ..., 4, 4, 6]]), array([[0, 4, 5, ..., 5, 4, 0],\n",
      "       [0, 4, 5, ..., 5, 5, 0],\n",
      "       [0, 4, 5, ..., 5, 5, 0],\n",
      "       ...,\n",
      "       [0, 4, 5, ..., 5, 5, 1],\n",
      "       [0, 5, 5, ..., 5, 5, 1],\n",
      "       [0, 5, 5, ..., 5, 5, 2]]), array([[5, 6, 6, ..., 0, 4, 0],\n",
      "       [0, 6, 0, ..., 0, 4, 0],\n",
      "       [0, 6, 0, ..., 0, 4, 0],\n",
      "       ...,\n",
      "       [3, 4, 0, ..., 3, 4, 0],\n",
      "       [3, 2, 0, ..., 3, 4, 0],\n",
      "       [3, 3, 0, ..., 4, 2, 0]]), array([[0, 0, 0, ..., 2, 2, 0],\n",
      "       [0, 0, 3, ..., 2, 2, 0],\n",
      "       [0, 0, 3, ..., 2, 3, 0],\n",
      "       ...,\n",
      "       [0, 4, 3, ..., 2, 3, 0],\n",
      "       [0, 4, 4, ..., 2, 3, 0],\n",
      "       [6, 2, 3, ..., 2, 2, 0]]), array([[0, 1, 4, ..., 4, 4, 0],\n",
      "       [2, 2, 4, ..., 4, 4, 0],\n",
      "       [2, 2, 4, ..., 0, 4, 0],\n",
      "       ...,\n",
      "       [3, 3, 3, ..., 5, 4, 0],\n",
      "       [3, 3, 3, ..., 5, 5, 0],\n",
      "       [4, 4, 4, ..., 5, 5, 0]]), array([[0, 3, 4, ..., 6, 0, 0],\n",
      "       [0, 3, 3, ..., 0, 0, 0],\n",
      "       [0, 5, 3, ..., 0, 0, 0],\n",
      "       ...,\n",
      "       [0, 4, 4, ..., 0, 0, 0],\n",
      "       [0, 4, 3, ..., 0, 0, 0],\n",
      "       [0, 3, 3, ..., 4, 0, 0]]), array([[0, 0, 0, ..., 3, 0, 0],\n",
      "       [0, 6, 5, ..., 4, 0, 0],\n",
      "       [0, 6, 0, ..., 4, 0, 0],\n",
      "       ...,\n",
      "       [0, 5, 3, ..., 4, 0, 0],\n",
      "       [0, 5, 3, ..., 5, 0, 0],\n",
      "       [0, 5, 0, ..., 5, 0, 0]]), array([[0, 0, 0, ..., 0, 2, 2],\n",
      "       [0, 0, 0, ..., 0, 2, 2],\n",
      "       [0, 0, 0, ..., 0, 2, 2],\n",
      "       ...,\n",
      "       [0, 0, 0, ..., 0, 2, 2],\n",
      "       [0, 6, 0, ..., 5, 4, 3],\n",
      "       [2, 6, 0, ..., 4, 4, 4]])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/aws_neuron_tensorflow_p36/lib/python3.6/site-packages/ipykernel_launcher.py:76: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
      "/home/ubuntu/anaconda3/envs/aws_neuron_tensorflow_p36/lib/python3.6/site-packages/numpy/core/fromnumeric.py:3335: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/home/ubuntu/anaconda3/envs/aws_neuron_tensorflow_p36/lib/python3.6/site-packages/numpy/core/_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>compiled_batch_size</th>\n",
       "      <th>user_batch_size</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>first_prediction_time</th>\n",
       "      <th>average_prediction_time</th>\n",
       "      <th>wall_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>inf1_compiled_batch_size_1_compiled_cores_1</th>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>12.1512</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.5359</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            compiled_batch_size  \\\n",
       "inf1_compiled_batch_size_1_compiled_cores_1                   1   \n",
       "\n",
       "                                            user_batch_size accuracy  \\\n",
       "inf1_compiled_batch_size_1_compiled_cores_1              64        0   \n",
       "\n",
       "                                            first_prediction_time  \\\n",
       "inf1_compiled_batch_size_1_compiled_cores_1               12.1512   \n",
       "\n",
       "                                            average_prediction_time wall_time  \n",
       "inf1_compiled_batch_size_1_compiled_cores_1                     NaN   12.5359  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>inf1_compiled_batch_size_1_compiled_cores_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>compiled_batch_size</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_batch_size</th>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>first_prediction_time</th>\n",
       "      <td>12.1512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>average_prediction_time</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wall_time</th>\n",
       "      <td>12.5359</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        inf1_compiled_batch_size_1_compiled_cores_1\n",
       "compiled_batch_size                                               1\n",
       "user_batch_size                                                  64\n",
       "accuracy                                                          0\n",
       "first_prediction_time                                       12.1512\n",
       "average_prediction_time                                         NaN\n",
       "wall_time                                                   12.5359"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_type = 'xception'\n",
    "# https://github.com/tensorflow/tensorflow/issues/29931\n",
    "temp = tf.zeros([8, 224, 224, 3])\n",
    "_ = models[model_type].preprocess_input(temp)\n",
    "\n",
    "# testing batch size\n",
    "batch_list = [1]\n",
    "num_of_cores = [1]\n",
    "user_batchs = [64]\n",
    "inf1_model_dir = f'{model_type}_inf1_saved_models'\n",
    "\n",
    "for user_batch in user_batchs:\n",
    "    iter_ds = pd.DataFrame()\n",
    "    results = pd.DataFrame()\n",
    "    for batch_size in batch_list:\n",
    "        for num_cores in num_of_cores:\n",
    "            opt ={'batch_size': batch_size, 'num_cores': num_of_cores}\n",
    "            compiled_model_dir = f'{model_type}_batch_{batch_size}_inf1_cores_{num_cores}'\n",
    "            inf1_compiled_model_dir = os.path.join(inf1_model_dir, compiled_model_dir)\n",
    "\n",
    "            print(f'inf1_compiled_model_dir: {inf1_compiled_model_dir}')\n",
    "            col_name = lambda opt: f'inf1_{batch_size}_multicores_{num_cores}'\n",
    "\n",
    "            res, iter_times = inf1_predict_benchmark_single_threaded(inf1_compiled_model_dir,\n",
    "                                                                             batch_size = batch_size,\n",
    "                                                                             user_batch_size = batch_size*user_batch,\n",
    "                                                                             num_cores = num_cores,\n",
    "                                                                             use_cache=False, \n",
    "                                                                             warm_up=10)\n",
    "\n",
    "        iter_ds = pd.concat([iter_ds, pd.DataFrame(iter_times, columns=[col_name(opt)])], axis=1)\n",
    "        results = pd.concat([results, res], axis=1)\n",
    "    display(results)\n",
    "    results.to_csv(f'{model_type}_batch_size_{batch_size}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aws_neuron_tensorflow_p36_2",
   "language": "python",
   "name": "aws_neuron_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
